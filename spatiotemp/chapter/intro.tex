% siminos/spatiotemp/chapter/intro.tex
% $Author: mgudorf3 $ $Date: 2020-02-28 13:50:57 -0500 (Fri, 28 Feb 2020) $

% called by
%           siminos/spatiotemp/chapter/spatiotemp.tex
%           siminos/tiles/GuBuCv17.tex

%\section{Introduction}
%\label{sect:intro}
% Predrag                                           12 January 2016

%%%%%% an example for Matt - illustrates use of \edit for REFEREE resubmissions
\edit{
Recent experimental and theoretical advances \rf{science04}
support a dynamical vision of turbulence:
For any finite spatial resolution,
a turbulent flow follows approximately for a finite time
a pattern belonging to a
{ finite alphabet}
of admissible patterns.
The long term dynamics is
a {walk through the space of these unstable patterns}.
The question is how to characterize and classify such patterns?
} %end \edit
\MNG{2020-01-20}{ [Background] }
%\subsection{Background}
%	\subsubsection{The problem at hand}
Chaotic nonlinear systems constitute one of the few classical
physics problems yet to be solved. The behaviors exhibited are so peculiar
that it has permeated into popular culture via the butterfly effect.
This behavior poses a serious challenge which has
effects everything from weather prediction to
air travel. 
%	\subsubsection{Minimal cells}
In the recent past computational successes were made
by studying turbulent flows on minimal cells: small domains that
could support turbulence and remain computationally tractable.
%	\subsubsection{ECS}
These successes came in form of time invariant solutions
alkso known as ``exact coherent structures''
(ECS) \rf{W01, WK04}. These solutions are important because it
is their unstable and stable manifolds that dictate the dynamics \rf{WFSBC15}.
%\subsubsection{large}
Not only have conventional methods not worked on large domains, we argue that
they never could have worked. The motivation behind minimal cells was to
develop an intuition for turbulence which would be used to obtain results
on progressively large domains. 

%    \subsubsection{space-time is the new black}
In light of all of these difficulties 
we believe that new bold ideas are required to resume forward progress.
We retreat from the conventional wisdom to start anew with a truly
{\spt} theory, one that treats infinite space-time as the shadowing
of a finite number of fundamental patterns which we denote as ``tiles''.  




\MNG{2020-01-20}{ [Revolution] WHY?}
%\subsubsection{main motivation, treat dimensions equally}
The primary claim that we make is that in hindsight, describing turbulence
via an exponentially unstable dynamical equation never could have worked. 
Conventional methods treat spatial dimensions
as finite and fixed and time as inherently infinite.
Our {\spt} formulation of chaos treats all continuous dimensions with translational
invariance democratically as $(1+D)$ different `times'. 
The proposal is inspired by the Gutkin and Osipov \rf{GutOsi15}
modelling of chain of $N$ coupled particle by temporal evolution of a
lattice of $N$ coupled cat maps.

%\subsubsection{characterize and quantify all patterns}
The alternative that we propose to describe infinite space-time chaos via
the shadowing of fundamental patterns which we refer to as ``tiles''.
These tiles are the minimal ``building blocks'' of turbulence; they are realized
as \twots\ which are global solutions with compact support. 
Finding the tiles of turbulence is fundamentally easier than finding
\twots\ on larger domains due to the exponential growth in complexity of
solutions. In other words there are fewer important solutions on smaller
domains. This in turn implies that there can only be a small
number of fundamental tiles. This is what makes the problem tractable:
if we can collect the complete set of tiles then we have the ability to
construct every \twot\ according to our theory.

%\subsubsection{no instabilities}
The lack of exponentially unstable dynamics has powerful and immediate effects.
Because there is no time integration, the problem of finding \twots\ is
now a variational one. The benefit of this is that there is no need to start
an initial guess on the attractor; the optimization process handles this
entirely. This allows us to find arbitrarily sized \twots but in fact
there is no need to. Our hypothesis is that we need only to find the
building blocks which shadow larger \twots\ and infinite space-time.

%\subsubsection{Large to small}
The {\spt} formulation allows a much easier categorization of what is
``fundamental'' by virtue of the frequency that patterns admit in the
collection of \twots. By identifying the most frequent patterns, we shall
clip these patterns out of the \twots\ they shadow and use them as initial
conditions to search for our tiles.  


%\subsubsection{small to large}
The notion of ``building blocks of turbulence'' is one of the reasons for
studying fluid flows in the first place. There is evidence that certain
physical processes are fundamental, but they have yet to be used in a
constructive manner. The {\spt} description is able to actually put
these ideas in practice. 
The \spt\ completely avoids this by constructing larger \twots\
from the combination of smaller \twots. 
The reason
why the search for the fundamental tiles is classified as ``easy'' is because
in the small domain size limit there just aren't that many \twots; the dynamics
is relatively simple.

%\subsubsection{numerical benefits?}
The first key difference is that the governing equation
dictates the \spt\ domain size in an unsupervised
fashion. The results here are not  
The only reason why $L$ was treated as fixed is due to the
inherent instability it includes when treated as a varying quantity.
This small detail, allowing the domain size $L$ to vary,
is not as trivial as it seems.
 This difficulty
is especially evident in the \KSe, whose spatial derivative terms
are of higher order than the first order time derivative, but also
there is a spatial derivative present in the nonlinear component.


%\subsubsection{easier to scale}

%\subsection{Transition}
%    \subsubsection{Advantages of spatiotemporal in place, what to do}

Specifically, we propose to study the evolution of \KS\ on the $2$\dmn\ infinite
{\spt}domain and develop a $2$\dmn\ symbolic dynamics for it: the
columns coding admissible time itineraries, and rows coding the
admissible spatial profiles. Our {\spt} method is the clear winner in both a computational and theoretical sense. By converting to a tile based shadowing description we have essentially
removed the confounding notion of an infinite number of infinitely complex {\twots}
from the discussion. Now we must put these ideas into practice. 
%\subsection{What}
%	\subsubsection{KSe, comparison with navier stokes}
The testing grounds for these ideas will be the \spt\ \KSe
% Are we relabeling all equations?
\beq \label{e-ks}
u_t + u_{xx} + u_{xxxx} + u u_x = 0 \quad \mbox{where} \quad x \in [0,L], t\in [0,T]
\eeq
where $u = u(x, t)$ represents a \spt\ velocity field. This
equation has been used to model many different processes such as
the laminar flame front velocity of Bunsen burners.
While \refeq{e-ks} is much simpler than the {\spt} Navier-Stokes equation,
we would argue that the main benefit is the simplicity of
visualizing its two-dimensional space-time. This visualization
makes the arguments more understandable and compelling in addition
to making the tiles easier to identify. 
%\subsubsection{2-tori translational invariance, Fourier}
The translational invariance and periodicity of \refeq{e-ks} make
\spt\ Fourier modes a natural choice.
The inherently infinitely dimensional equations are approximated
by a Galerkin truncation of these \spt\ Fourier modes.
The \KSe\ \refeq{e-ks} in terms of the \Fcs\ $\Fu$ is a
system of differential algebraic equations
$\Fu$
\bea \label{e-kssFb}
%KSe in Fourier basis, pseudo-spectral form.
F(\Fu, L, T) &\equiv& (\omega - k^2 + k^4) \Fu + \frac{k}{2} \FFT(\IFFT(\Fu)^2)\,.
\eea
The nonlinear term is computed in a \emph{pseudospectral} fashion: a method which computes the
nonlinear term as a product in physical space as opposed to a convolution in spectral space.
The definitions of each term is as follows; $\FFT$ and $\IFFT$ represent the forward and backwards
\spt\ Fourier transform operators. Likewise, $\omega$ and $k$ contain the appropriate temporal and spatial frequencies to produce the corresponding derivatives. Any and all indices are withheld
to avoid unnecessary confusion at this stage.
%	\subsubsection{optimization problem (engineer's know how to solve)}
The {\spt} system of differential algebraic equations \refeq{e-kssFb} 
is of the form $F(\Fu, L, T)=0$. This type of optimization problem is ubiquitous in
engineering and optimization literature. Therefore solving \refeq{e-kssFb} is a matter of
adapting known numerical methods to its idiosyncracies.
%	\subsubsection{library of solutions}
Once we have the ability to solve \refeq{e-kssFb} we need to first create a collection
of \twots. The only requirement that the collection must satisfy is that it must capture
all fundamental patterns by adequately sampling the set of \twots. In other words an exhaustive
search is not our aim; not only that, but also the collection need not sample all {\spt} domain sizes.
We hypothesize that there is some upper bound on the {\spt} size of fundamental tiles due to {\spt}
correlation lengths. 
%	\subsubsection{large to small}
Once the collection is deemed sufficient we proceed to visual inspection. In this manner
we determine the most frequent patterns and single them out as tile candidates. This is
done by literally clipping them out of the \twots\ that they shadow. Each clipping is
then treated as an initial guess for a fundamental tile which is itself a \twot. Therefore,
these represent initial conditions for the optimization method. It is not a guarantee
that every clipping converges to a \twot; therefore the number of attempts to find a tile
should continue until it does in fact converge. The number of convergence attempts is typically
proportional to how confident we are that the pattern being scrutinized is in fact a tile.
%	\subsubsection{small to large}
Once a collection of tiles is collected, we can construct new and reproduce known \twots. 
This is completed with a method we refer to as ``gluing''. It is as straightforward as one
might infer: tiles are combined in a {\spt} array to form initial conditions used to find larger
\twots. Methods of gluing temporal sequences of \twots\ exist but never has the ability to
glue \twots\ spatiotemporally existed before.
%\subsubsection{symbolic dynamics}
With the implementation of the gluing method can begin to 
probe the 2\dmn\ {\spt} symbolic dynamics
previously mentioned. A fully determined symbolic dynamics is sufficient
to describe infinite space-time completely. 
We already have the two edges of this symbol plane - the $\speriod{}=22$ minimal
cell\rf{SCD07,lanCvit07} is sufficiently small that we can think of it as
a low-dimensional (``few-body'' in Gutkin and Klaus
Richter\rf{EPUR14,EDASRU14,EnUrRi15,EDUR15} condensed matter parlance)
dynamical system, the left-most column in the Gutkin and
Osipov\rf{GutOsi15} $2D$ symbolic dynamics {\spt} table (not a
1\dmn\ symbol sequence block), a column whose temporal symbolic dynamics
we will know, sooner or later. Michelson\rf{Mks86} has described the
bottom row. The remainder of the theory will be developed from the
bottom up, starting with small {\spt} blocks.

%\subsubsection{Summary and transition}
The plans for our {\spt} formulation have been laid bare. The main concept is that the infinities
of turbulence can be described by {\spt} symbolic dynamics whose letters are fundamental {\spt}
patterns. Consequentially, we have created numerical methods which not only perform better than
conventional methods but also present incredible newfound capabilities. These newfound capabilities
include but are not limited to finding small \twots\ which shadow larger \twots\ but also constructing
larger \twots\ from smaller ones. These new and robust methods alone present a way forward for turbulence research, hence their is merit in a {\spt} formulation even though the theory has not
been fully fleshed out.
%\subsection{Transition}
To test our \spt\ ideas we require three separate numerical methods: the first
should be able to find \twots\ of arbitrary domain size. The second needs to be able to
clip or extract tiles from these \twots. Lastly, we need a method of
gluing these tiles together. All three of these techniques require the ability
to solve the optimization problem $F(\Fu, T, L)=0$
on an arbitrarily sized doubly periodic domain.

\MNG{2020-02-18}{How?}
%\subsubsection{initial conditions}
As previously discussed, this work does not use
approximate recurrences or time integration
to generate initial conditions. Instead we simply
initialize a lattice of Fourier modes by first deciding
on the dimensions of the lattice and then assigning random 
values to the modes. Specifically, random values in this case are
drawn from the standard normal distribution and then normalized
such that the physical field $u(x,t)$ has the assigned maximum value.
Manipulations of the Fourier spectrum can also be made but we have
no specific recommendation for how to do so as it can be rather
unintuitive.  

%\subsubsection{gradient descent}
The first method substitutes an equivalent optimization problem
instead of directly solving $F=0$. The optimization
problem is formed by the construction
of a scalar cost function
\beq
\mathcal{I}(\Fu, T, L) = \frac{1}{2}||F(\Fu, T, L)||_2^2 \,.
\eeq
taking a derivative with respect to a fictitious time $\tau$
\bea \label{e-descent}
\frac{\partial \mathcal{I}}{\partial \tau} &=& \nabla
\Big(\frac{1}{2}||F(\Fu, T, L)||_2^2\Big) \partial_{\tau}[\Fu, T, L] \continue
&=&
\Bigg(\Big[\frac{\partial F}{\partial \Fu}, \frac{\partial F}{\partial T},
\frac{\partial F}{\partial L} \Big]^{\top} F(\Fu, T, L)\Bigg) \cdot \partial_{\tau}[\Fu, T, L] \continue
&\equiv& \Big(J^{\top}F\Big) \cdot \partial_{\tau}[\Fu, T, L] \quad .
\eea
This equation \refeq{e-descent} by itself does not provide us with a descent direction
because $\partial_{\tau}[\Fu, T, L]$ remains unspecified.
The simplest choice is the
negative gradient of the cost function; this choice
corresponds to the gradient descent algorithm.
\beq
\partial_{\tau}[\Fu, T, L] = - \Big(J^{\top}F\Big) \,,
\eeq
such that
\beq
\frac{\partial \mathcal{I}}{\partial \tau} = -\Big|\Big| \Big(J^{\top}F\Big)\Big|\Big|_2^2 \leq 0 \,.
\eeq
In order to ``descend'' we use Euler's method to integrate in the
descent direction. Note that
this integration is with respect to fictitious time and represents making
successive variational corrections; it is not dynamically unstable time integration. 
We elect to use a combination of step limit and absolute tolerance to determine
when the descent terminates. If the
cost function doesn't cross the threshold by the step limit then the descent is terminated.
The descent algorithm can be viewed as a method of converging approximate solutions
close enough to a final \twot\ such that the least-squares algorithm can converge them, akin
to \rf{Faraz15}.

%\subsubsection{direct methods}
The second method is application of a least-squares solver 
to the root finding problem $F=0$. The Newton system is
derived here for context.
\beq
F(\Fu+\delta\Fu, T+\delta T, L+\delta L)\approx
F(\Fu, T, L) + J \cdot [\delta\Fu, \delta T, \delta L] + \dots \,.
\eeq
substitution of zero for the LHS (the root) yields
\beq \label{newton}
J \cdot [\delta\Fu, \delta T, \delta L] = -F(\Fu, T, L) \,.
\eeq
where
\beq
J \equiv \Big[\frac{\partial F}{\partial \Fu}, \frac{\partial F}{\partial T}, \frac{\partial F}{\partial L} \Big] \,.
\eeq
Technically this equation is solved iteratively, each time producing its own least-squares solution which guides the field to \twot. The equations are augmented to include variations in $T,L$ and as
such the linear system is actually rectangular.
We chose to solve the equations in a least-squares manner as we are not focused on finding a unique
solution; any member of a \twots\ group orbit will do. The price of this indefiniteness is that we might
collect \twots\ which belong to the same group orbit. To improve the convergence rate of the algorithm we also include backtracking: the length of the Newton step is reduced until either a minimum length is reached (failure) or the cost function decreases. 
%\subsubsection{transition to applications}
As a caveat, our specific least-squares
implementation is memory limited. That is, we can only apply it to some maximum dimension as it requires
the explicit construction of a large, dense matrix. Currently it suits our purposes such that we do not include any other numerical methods in this discussion.
The primary numerical methods that we apply have been described. 
Now we can move onto describing exactly
how we used these method to further our \spt\ theory.
 
%\subsubsection{library}
As previously mentioned, we must first find a collection of \twots\ which we believe
adequately samples the space of \twots, up to some maximum size. We automated the search over a range
of periods and domain sizes. Periods were chosen from the range
$T\in [20, 180]$. Meanwhile, the spatial range was $L \in [22, 88]$. The discretization size
depended on the \spt\ domain size; more modes are needed to resolve larger solutions. The number
of lattice points in each dimension were typically chosen to be powers of two in order because of their interaction with discrete Fourier transforms. A strict rule for lattice size
was never developed so we offer is the approximate guidelines
\beq
M = 2^{\text{int}(log_2(L)+1)}
\eeq
for space and
\beq
N = 2^{\text{int}(log_2(T))}\,.
\eeq
for time.
The tolerance of the cost function for the gradient descent was typically set at $10^{-4}$
and the step limit was set as a function of the size of the lattice. For the least-squares
with backtracking the tolerance for termination was originally $10^{-14}$ and the step limit was $500$. The large step limit was because of
the allowance of back-tracking, which reduces the step length.
The final tolerance can likely be relaxed as there is minimal change in solutions over many orders
of magnitude of the cost function; an indication that a different norm should be used.
%\subsubsection{clip}
As a reminder, our claim is that the tiles are \twots\ which shadow larger \twots.
Therefore we should be able to converge subdomains which have been numerically clipped out
of larger \twots. After visual inspection, we believed the number of fundamental tiles to
be small. Therefore, a precise and unsupervised algorithm for clipping was not developed.
Instead the only criteria we abided by is that the clipping must include the tile being
sought after; of course, clippings that were closer to being doubly periodic were sought after.
For the original \twot\ with dimensions $x \in [0, L_0]$ and $t \in [0, T_0]$ defined on a lattice, the
clipping can be described as follows. Find the approximate domain on which
the shadowing occurs and then literally extract the subregion of the parent lattice,
setting the new {\spt} dimensions according to the smaller lattice. In other words,
the same grid spacing was maintained throughout this procedure. 
This process in combination with our numerical methods was sufficient
for finding tiles. 
%\subsubsection{glue}
It is one thing to claim that certain \spt\ \twots\ are the building blocks
of turbulence for the \KSe. It is
another thing entirely to put our money where our mouth is by actually using them in this manner. We would like to remind the audience that the ability to construct and find solutions in this manner
has not been witnessed in the literature. With this in mind our choices should
be treated as preliminary ones; it is entirely possible and likely that
many improvements could be made. 
Much like the clipping process used to find tiles combining solutions in space-time,
the overarching idea of gluing is straightforward and intuitive. 
Specifically, the tiles represent the 
Brillouin zone, fundamental domain, unit cell of a lattice, etc.
of each fundamental \twot. 
The general case is that we have a general $s_n \times s_m$ sized mosaic of tiles.
The admissibility of the gluing is determined by the (currently unknown) symbolic
dynamics. Gluing is only well defined if the lattices being combined have the same
number of grid points along the gluing boundary.
This creates a problem, however, as
different tiles will have different \spt\ dimensions $T,L$ because
they are fundamentally different solutions.
This actually helps provide a precise meaning to the term ``gluing''.
Gluing is a method of creating initial conditions which approximates
a non-uniform rectangular lattice (combination of tiles) as uniform. 
This of course introduces local error which depends on the grid size; therefore
there should not be an extreme discrepancy between the \twots\ or tiles being glued.
With this in mind, we simply rediscretize and concatenate the new lattices.
The dimensions of the new lattice are determined by the sum or average of
the original dimensions.
For example, if gluing two tiles together in time, the new period would be
$T = T_1 + T_2$ but the new spatial period is$L = \frac{L_1 + L_2}{2}$.
In this case the number of spatial grid \emph{points} and temporal grid \emph{spacing}
should be the same. There are many more complicated alternatives, limited only by
the imagination.
