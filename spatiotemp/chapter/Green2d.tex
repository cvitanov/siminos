% siminos/spatiotemp/chapter/Green2d.tex
% $Author: predrag $ $Date: 2021-08-10 11:56:19 -0400 (Tue, 10 Aug 2021) $

\renewcommand\speriod[1]{{\ensuremath{\ell_{#1}}}}  %continuous spatial period
\renewcommand\period[1]{{\ensuremath{\ell_{#1}}}}  %continuous time period

\section{Helmoltz type equations}
\label{sect:Helmoltz}

The inhomogeneous \emph{Helmoltz equation} is an elliptical equation of form
\beq
   (\Box+k^2)\,\field(x)= -4\pi\rho(x)\,,\qquad x\in \reals^d
\,,
\label{CatMapContinuesPC}
\eeq
where the field $\field(x)$ is a $C^2$ function of coordinates, and
$\rho(x)$ is a density function with compact support.
Its Green's function satisfies
\begin{equation}
 (\Box+k^2)\,g(x,x')=\delta(x-x')
\,.
\label{GreenFunContinuesPC}
\end{equation}
% cribbed from https://webhome.phy.duke.edu/~rgb/Class/phy319/phy319/node74.html
For example, in $d=3$ dimensions the stationary wave, the outgoing wave and the
incoming wave Green's functions are:
\bea
g_0({x},x') &=& -\frac{\cos(k\vert x- x'\vert)}{4\pi\vert{x}- x'\vert}
\continue
g_+({x},x') &=& -\frac{\e^{ik\vert{x}- x'\vert}}{4\pi\vert{x}- x'\vert}
\continue
g_-({x},x') &=& -\frac{\e^{-ik\vert{x}- x'\vert}}{4\pi\vert{x}- x'\vert}
\,.
\label{GreenFunContinuesPC1}
\eea
Furthermore, to these any solution to the homogeneous Helmholtz equation
\[
(\Box+k^2)\,f_0({x},x') = 0
\]%{GreenFunContinuesPC2}
can be added.
On infinite space, the solution of \refeq{CatMapContinuesPC} is of the form
\beq
\field(x) = \field_0(x) - \int_V \!d^dx'\,{\rho}(x')\,g(x,x')
\,,
\ee{GreenFunContinuesPC3}
where $(\Box+k^2)\,\field_0(x)=0$.

\subsection{Poisson and Laplace's equations}
\label{sect:PoissLap}

The \emph{Poisson equation} is the $k \to 0$ limit of the Helmholtz equation;
\beq
   \Box\,\field(x)= -4\pi\rho(x)\,,\qquad x\in \reals^d
\,,
\ee{PoissonEq}
with Green's function
\beq
g({x},x') = -\frac{1}{4\pi\vert{x}- x'\vert}
\,.
\ee{PoissonGreenFunc}
For $\rho=0$, the equation is known as \emph{Laplace's equation}.

\subsection{\SPe}
\label{sect:SPe}

For
the ${\mu}^2=-k^2>0$ (imaginary $k$), the equation
\beq
   (-\Box + {\mu}^2)\,\field(x)= 4\pi\rho(x)\,,\qquad x\in \reals^d
\,,
\label{sPe}
\eeq
is known as  the {\em
{\sPe}}\rf{FetWal03}, Klein–Gordon or \emph{Yukawa equation}.

The name arises from its applications to electric field screening in
plasmas. In chemistry the equation governs steady-state diffusion in
presence of the solute $\rho(x)$ piped in or
generated by a chemical reaction, or of heat diffusion in presence of
heat sources.

The solutions of the {\sPe} \refeq{sPe} are of the same form as for the
Helmholtz equation, but with the oscillatory $\sin,\cos$, and $\exp(i
\cdots)$ solutions replaced by the hyperbolic $\sinh,\cosh$, and
$\exp(-\cdots)$.

The outgoing Green's
function \refeq{GreenFunContinuesPC1} is here known as the \emph{Yukawa
potential},  the static, spherically symmetric solution
\beq
g({x},x') = -\frac{\e^{-{\mu}\vert{x}- x'\vert}}{4\pi\vert{x}- x'\vert}
\,.
\label{GreenFunYukawa}
\eeq
 to the Klein–Gordon equation.
% https://en.wikipedia.org/wiki/Yukawa_potential
The Fourier transform relates the Yukawa potential to the
massive scalar particle
propagator, \ie, Green's function of the static Klein–Gordon equation
\refeq{KleinGnat},
\[
V(\mathbf{r})
=\frac{-g^2}{(2\pi)^3} \int \e^{i\mathbf{k \cdot r}}
\frac {4\pi}{k^2+{\mu}^2} \;\operatorname{d}^3\!k
\,.
\]
In $d=2$ this integral can be explicitly evaluated as a
Bessel function,
    \PC{2020-10-31} {Recheck the $2\pi$ factors}
% https://en.wikipedia.org/wiki/Screened_Poisson_equation
\beq
g(\mathbf{r},0)
= \frac{1}{2\pi} \; \int_{0}^{+\infty} \mathrm{d}k_r \;
   \frac{k_r \, J_0(k_r r)}{k_r^2 + {\mu}^2} = \frac{1}{2\pi} K_0(r{\mu}).
\eeq


\subsection{Klein–Gordon equation}
\label{sect:KleinGord}

\HREF{https://en.wikipedia.org/wiki/Klein-Gordon_equation}
{wiki says}:
The Klein–Gordon equation for a scalar particle of mass ${m}$
and complex-valued function $\psi(t,\mathbf{x})$
of the time variable $t$ and space variables $\mathbf{x}$,
\beq
\frac{1}{c^2} \frac{\partial^2}{\partial t^2}\psi - \nabla^2 \psi
  + \frac{m^2 c^2}{\hbar^2} \psi = 0
\,,
\ee{KleinGeq}
is derived by requiring that its plane-wave solutions
\beq
\psi = \e^{-i\omega t + i \mathbf{k}\cdot\mathbf{x}} = \e^{i k_\mu x^\mu}
\ee{KleinGpWave}
obey the energy–momentum relation of special relativity,
\beq
-p_\mu p^\mu = E^2 - \mathbf{p}^2
   = \omega^2 - \mathbf{k}^2 = -k_\mu k^\mu = {\mu}^2
\,,
\ee{KleinGenMom}
with $(-, +, +, +)$ metric. It is written compactly in {\em natural
units},
\beq
(\Box + \mu^2) \psi = 0
\,,
\ee{KleinGeqAbrv}
where $\mu=mc/\hbar$, and
\beq
\Box = -\partial_\nu\partial^\nu
   = \frac{1}{c^2} \frac{\partial^2}{\partial t^2} - \nabla^2
\ee{KleinGdAlem}
is the {\em d'Alembert operator},
while the scalar operator
% The Laplacian operator $\nabla^2$ is often written as $\Delta$.
\beq
\Delta=\nabla^2 =  \frac{\partial^2~}{\partial x^2}
          + \frac{\partial^2~}{\partial y^2}
          + \frac{\partial^2~}{\partial y^2}
\,,
\ee{GraRyzSect10.31}
is called the \emph{Laplacian} or the \emph{Laplace operator}.

Writing the equation as
\beq
-\partial_t^2 \psi + \nabla^2 \psi = {\mu}^2 \psi
\,,
\ee{KleinGnat}
we note that for the time-independent solutions, the Klein–Gordon equation
becomes the homogeneous {\em\sPe}
\beq
\left(\nabla^2 - {\mu}^2\right) \psi(\mathbf{r}) = 0
\,.
\ee{KleinGtInd}

\subsection{\catLatt\ equation}
\label{sect:catLatt}

The Yukawa massive field mass parameter is related to the \catlatt\
stretching parameter ${s}$ by % as in \refeq{catlattMass}
\beq
{\mu}^2=d(s-2)
\,.
\ee{catlattMass}
The $d$\dmn, purely hyperbolic ${\mu}^2>0$
{\catlatt} % \refeq{catLattPC}
\beq % PC rescaled {s} 2020-09-20
 (-\Box + {\mu}^2\unit)_{zz'} \field_{z'} = - \m_z
    \,, \qquad
  \field_{z} \in  \mathbb{T}^{1}
    \,, \quad
  m_{z} \in \A^{1}
    \,, \quad
  z\in \integers^{d}
\,,
\ee{GreenLinearConnPC}
that we study is a discretization of the inhomogeneous {\em\sPe}
\refeq{KleinGtInd}, while the discretization of the Helmholtz equation
corresponds to $s<2$.

We denote the differential operator by the d'Alembert $\Box$ rather than
the {Laplacian} $\Delta$ \refeq{GraRyzSect10.31} to emphasize that we are
studying the \spt\ \catlatt\ rather than the temporally static solutions
\refeq{KleinGtInd}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Helmholtz blog}
\label{sect:HelmBlog}

\HREF{https://en.wikipedia.org/wiki/Screened_Poisson_equation} {wiki}:
In the inhomogeneous case, the only difference between the inhomogeneous
{\sPe} and the inhomogeneous Helmholtz equation is the the sign of the
${\mu}^2$ parameter.

\begin{description}
	\item[2020-10-31 Predrag]
In sect.~1.30 \emph{Introduction}, {Gradshteyn and Ryzhik} write:

The trigonometric and hyperbolic sines are related by the identities
\beq
\sinh x = \frac{1}{i}\sin(ix)
\,,\qquad
\sin x = \frac{1}{i}\sinh(ix)
\,.
\ee{GraRyzSect1.30sin}
The trigonometric and hyperbolic cosines are related by the identities
\beq
\cosh x = \cos(ix)
\,,\qquad
\cos x = \cosh(ix)
\,.
\ee{GraRyzSect1.30cos}
Because of this duality, every relation involving trigonometric functions
has its formal counterpart involving the corresponding hyperbolic
functions, and vice versa. In many cases, both pairs of
relationships are meaningful.

In sect.~6.94 \emph{Relationships between eigenfunctions of the Helmholtz
equation in different coordinate systems} they
define the scalar Helmholtz equation
as
\beq
(\nabla^2+k^2)\Psi=0
\,,
\ee{GraRyzSect6.94a}
with a 3\dmn\ Laplacian
\refeq{GraRyzSect10.31}, and a
Cartesian particular solution of form
\beq
\Psi_{k_x k_y k_z}(x,y,z)\propto \e^{i(k_x x+k_y y+k_z z)}
\mbox{ with }
k^2 = k_x^2+k_y^2+k_z^2
\,.
\ee{GraRyzSect6.94b}

	\item[2017-09-09 Predrag]
Hu and {O'Connell}\rf{HuCon96} also state the discretized version of the
solution \refeq{PoissonGreenFunc} for $s=2$, which, unlike
\refeq{HuCon96(10)} has no exponentials - it's a power law.

I find
\HREF{http://www.damtp.cam.ac.uk/user/reh10/lectures/nst-mmii-chapter2.pdf}
{Robert E. Hunt notes} quite good, both for the continuum case, and for
solving the lattice discretization.

	\item[2020-10-31 Predrag]
In publications, it would be nice if we could refer to Gradshteyn and
Ryzhik\rf{GraRyz} whenever we mention continuum limits of our discretized
equations. It's the best known, classical reference.

Unfortunately, Gradshteyn and Ryzhik\rf{GraRyz} do not define the Laplace
equation and (damped?)
 {\sPe}, see
\HREF{https://en.wikipedia.org/wiki/Screened_Poisson_equation} {wiki}.
For that, we should combine our definitions
\refeq{GreenFunContinuesPC},
\refeq{Katsura1},
\refeq{Pozrikidis14(1.1.1)},
\refeq{Pozrikidis14(1.1.11)},
see also
{\bf 2017-09-09  Predrag},
{\bf 2020-01-13 Predrag},
and
discretizations of Helmholtz\rf{DiHaHu01,Lick89}
and screened Poisson%
\rf{Dorr70,BuGoNi70,GoVanLo96,HuCon96,HuRyCo98}
(also known as Klein–Gordon or Yukawa) equations.

	\item[2020-10-31 Predrag]
Relation to field theory is discussed in
\refsect{sect:lattDisc}~{\em Lattice discretization of a field theory}.

    \item[2018-09-26 Predrag]
The Lagrangian formulation \refeq{catLattPC} suggests that the action
(integral over the Lagrangian density, one-step generating function
\refeq{MKMP84(3.2)}) is given by
\beq
Z[\Mm] = \e^{W[\Mm]} = \int[d\Xx]\, \e^{S[\Xx]+\Xx\cdot\Mm}
    \,,
\ee{LagrDenPC}
\beq
W[\Mm]= \Gamma[\Xx]+\Xx\cdot\Mm
\,.
\ee{GibbsPC}
with ``source'' symbol \brick\ $\Mm$, free action
\beq
S[\Xx]=
- \frac{1}{2}\transp{\Xx}\left(-\Box + {\mu}^2\mathsf{1} \right)\Xx
\,,
\ee{LagrCurrPC}
and the Yukawa mass parameter ${\mu}^2=d(s-2)$ related to the \catlatt\
stretching parameter ${s}$ by \refeq{catlattMass}.

Were \Xx\ not confined to a unit hypercube,
the Gaussian integral for quadratic action
\beq
S[\Xx]=
-\frac{1}{2}\transp{\Xx}\left(-\Box + {\mu}^2\mathsf{1}\right)\Xx
\ee{ActionPC}
could be integrated out in the usual way,
\beq
Z[\Mm] = |\det(-\Box + {\mu}^2\mathsf{1})|^{-1/2}
\e^{\frac{1}{2}\transp{\Mm}(-\Box + {\mu}^2\mathsf{1})^{-1}\Mm}
    \,,
\ee{PartFreePC}
leading to
determinants and traces
\beq
W[0] = \ln Z[0] =-\frac{1}{2} \ln \det(-\Box + {\mu}^2\mathsf{1})
 =-\frac{1}{2} \tr \ln (-\Box + {\mu}^2\mathsf{1})
    \,.
\ee{W0PC}

    \item[2020-09-24 Predrag]
% Perhaps boyscout excerpt from ChaosBook.org \emph{det.tex}
% is suggestive:
The trace formula %\refeq{tr-L-cont}
is logarithmic derivative of the determinant,
% \PC{Fried relates the zeros to correlation spectrum}
\beq
    \tr \frac{1}{-\Box +{\mu}^2} =  \frac{d~}{d{\mu}^2}
          \ln \det(-\Box +{\mu}^2)
    \,.
\ee{der-det}
To recover $  \det(-\Box +{\mu}^2) $ integrate both sides
with respect to ${\mu}^2$,
\[
\int_{{\mu}_0^2}^{{\mu}^2}\!\!\!\!d{u} \;
    \tr \frac{1}{-\Box + {u}} =
    \ln \frac{\det(-\Box +{\mu}^2)}{\det(-\Box +{\mu}_0^2)}
\,,
\]
and exponentiate.
In this form, the determinant is regularized, as the divergent,
large wave-numbers $k$
contribution cancels out
\bea
    \frac{\det(-\Box +{\mu}^2)}{\det(-\Box +{\mu}_0^2)}
    &=&
\exp\left(
    \int_{{{\mu}_0^2}}^{{\mu}^2} \!\!\!\!d{u} \,\tr\frac{1}{-\Box + {u}}
    \right)
    \continue
    &=&
\exp\left(
    \int_{0}^\infty\!\!dt
    \int_{{\mu}_0^2}^{{\mu}^2}\!\!\!\!d{u}\,\tr \e^{-t(-\Box +{u})}
    \right)
    \continue
    &=&
\exp\left( -
    \int_{0}^\infty \! dt \frac{1}{t} \,
    \tr \!\left( \e^{-t(-\Box +{\mu}^2)} - \e^{-t(-\Box +{\mu}_0^2)}
        \right)
    \right)
\,.
\nnu
\eea
This appears to be the natural form of topological zeta functions, see
\refeq{AABHM99-56d}, with the Laplacian value ${\mu}_0=0$.


(Another variant, following worldline formalism:)
The free scalar propagator for the Euclidean
Klein-Gordon equation\rf{Schubert12,AhBaSc16} is
\beq
\gd_{z z'}=\left(\frac{1}{-\Box +\mu^2}\right)_{z z'}
\,.
\ee{Schubert12(1.1)}
% where $\Box$ is the $d$\dmn\ Laplacian.
Exponentiate the
denominator following Schwinger,
\beq
\gd_{z z'}=\int_0^\infty\!\!dt\,
           {e}^{-{\mu}^2 t}\left(\e^{-t(-\Box)}\right)_{z z'}
\,,
\ee{Schubert12(1.4)}
Replace the operator in the exponent by a path integral, \ie,
the sum over random walks
(see \HREF{http://chaosbook.org/FieldTheory/QMlectures/lectQM.pdf\#section.1.1}
{Wanderings of a drunken snail})
\beq
\gd_{z z'}=\int_0^\infty\!\!dt\,\e^{-{\mu}^2t}
\int_{x(0)=x'}^{x(t)=x}\!\!\!\!\mathcal{D}x(\tau)\,
    \e^{-\int_0^t\!\!d\tau \frac{1}{4}\dot{x}^2}
\,,
\ee{Schubert12(1.7)}
where $\tau$ is a proper-time parameter (the fifth parameter\rf{Fock37}), and
the dot denotes a derivative with respect to the proper time. This is the
\emph{worldline path integral} representation of the relativistic propagator
of a scalar particle in Euclidean space-time. In the vacuum (no background
field), it is easily evaluated by standard methods and leads to the usual
space and momentum space free propagators,
    \PC{2017-06-17}{
Here a study of Sect.~6. {\em Worldline formalism} of Gelis and
Tanji\rf{GelTan16} might be helpful - it reexpresses the integral as an
average over Wilson loops.
    }
\beq
\int_{x(0)=x'}^{x(t)=x}\!\!\!\!\mathcal{D}x(\tau)\,
    \e^{-\int_0^t\!\!d\tau \frac{1}{4}\dot{x}^2}
        =
\frac{1}{(4\pi t)^{d/2}}
\,,
\ee{GelTan16(186)}
should be one derivation of \refeq{GreenFunYukawa}.






\end{description}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bigskip\bigskip

Let $g(x,x')$, with $x,x' \in \R$ be the corresponding
Green's function  on  a  bounded, simply connected domain $\R\subset
\reals^d$,
satisfying some boundary condition  (e.g., periodic, Dirichlet or Neumann) at
$\partial \R$.
The Green's function identity allows us to connect the values of  $\ssp_{z}$
inside of $\R$ with the ones attained at the boundary (\BGedit{an arbitrary
Soviet citation}):
\begin{eqnarray}
 x(z) &=& \int_{\R} g(z,z')\m(z') dz'\nonumber \\
 &-& \int_{\partial \R} \nabla_n\,g(z,z'')x(z'')\,d z''
  +  \int_{\partial \R} \nabla_n\,x(z'') g(z,z'')\,d z''
\,.
 \label{GreensTheor}
\end{eqnarray}

The Neumann boundary condition can be imposed by extending the original field
symmetrically  across  its  sides,  so  that  the  extended field,  which  is
four  times  bigger,  is symmetric  and  periodic.


At the risk of sounding repetitive: it's crazy to formulate this problem in
terms of the symmetry-breaking domains with Dirichlet boundary conditions, when
all that is needed are the trivial periodic solutions on 2\dmn\ tori. To
appreciate how difficult the Dirichlet problem is, you can at your leisure
study the paper {\em On the solution of the {Helmholtz} equation on regions
with corners} by Soviet mathematicians Serkh and Rokhlin\rf{SerRok16} (one of
them a Member of The National Academy of Sciences of The USA), who solve
several boundary value problems for the Helmholtz equation on polygonal
domains. In terms of the boundary integral equations of potential theory, the
solutions are representable by series of appropriately chosen Bessel functions.
Making the space discrete does not make these calculations any easier.

\section{Green's  function for 2\dmn\ square lattice}
\label{sect:Green2D}
% was siminos/cats/Green.tex                        2017-09-06
%\renewcommand{\Ssym}[1]{{\ensuremath{m_{#1}}}} % Boris
% \newcommand{\Ssym}[1]{{\ensuremath{s_{#1}}}}  % ChaosBook

Copied to here from \emph{siminos/cats/GHJSC16.tex}    \hfill 2019-10-31

\bigskip

The free Green's function
$\gd(z,z')\equiv \gd(z-z',0)\equiv \gd_{z z'}$
solves  the equation
\begin{equation}
 (-\Box+ {\mu}^2)\gd_{z z'}=\delta_{zz'}
\,,\qquad
  z=(n,t) \in \integers^2
\,.
\label{GreenFun000}
\end{equation}
The solution is given by the double integral\rf{Martin06}
\beq
 \gd_{z0}=\frac{1}{\pi^2}\int_{0}^{\pi}\int_{0}^{\pi}\frac{\cos(nx)\cos(ty)}{s-2\cos x -2\cos y } dx dy
 \,,
\ee{GreenFun1}
an expression which can, in turn, be recast into single integral form,
\bea
 \gd_{z0} &=& \frac{1}{2\pi^3}\int_{-\infty}^{+\infty}d\eta\int_{0}^{\pi}\int_{0}^{\pi}\frac{\cos(nx)\cos(ty)}{(s/2-2\cos x -i\eta)(s/2 -2\cos y+i\eta) } dx dy
    \continue
    &=&
 \frac{1}{2\pi}\int_{-\infty}^{+\infty}d\eta\,
 \frac{\mathcal{L}(\eta)^{-n}\mathcal{L}^*(\eta)^{-t}}{|\mathcal{L}(\eta)-\mathcal{L}(\eta)^{-1}|^2 }
\,,
\label{GreenFun5}
\eea
where
\beq
\mathcal{L}(\eta)+\mathcal{L}(\eta)^{-1}= s/2+i\eta, \qquad  | \mathcal{L}(\eta)|>1
\,. \ee{Lfunc}

The above equation can be thought as the integral over a product of two
$\integers^1$ functions:
\beq
 \gd_{z0} =
 \frac{1}{2\pi}\int_{-\infty}^{+\infty}d\eta\,\gd_{n 0} (s/2+i\eta) \gd_{t 0} (s/2-i\eta)
\,.
\ee{GreenFun3}
An alternative representation is given by modified Bessel
functions $I_n(x)$ of the first kind\rf{Martin06}:
\beq
\gd_{z0} =\int_{0}^{+\infty}d\eta\,\e^{-s\eta} I_n(\eta) I_t (\eta)
\,,
\ee{GreenFun4}
which demonstrates that $ \gd_{z z'}$ is
positive for all $z=(n,t)$.
The representation (\ref{GreenFun4})
enables explicit evaluation of the $n=t$ diagonal elements
in terms of a Legendre function, % of the second kind,
\[
 \gd_{z0}=\frac{1}{2\pi i}Q_{n-1/2}(s^2/8-1 ),\qquad  s^2/8-1 >1, \quad z=(n,n)
 \,.
\]

\paragraph{Dirichlet boundary conditions.}
Consider next the Green's function $\gd_{zz'}$
% %\equiv\gd (z,z')% $z=(n,t) \in \integers^2$,  $z'=(n',t') \in \integers^2$
which  satisfies
\refeq{GreenFun000} within the rectangular domain
\(
\R=\{ (n,t) \in
\integers^2 |1 \leq n\leq \ell_1 , 1 \leq t\leq \ell_2    \}
\)
and vanishes at its boundary $\partial \R$, %, see \reffig{fig:block2x2}(a).
By applying the same method as in the case of 1\dmn\ lattices we  get
\begin{eqnarray*}
\gd_{zz'}
&=&\sum_{j_1,j_2=-\infty}^{+\infty}\!\!
\gd_{n-n'+2j_1(\ell_1+1), t-t'+2j_2(\ell_2+1)} +
\gd_{n+n'+2j_1(\ell_1+1),t+t'+2j_2(\ell_2+1)}\\
& &\qquad -\gd_{n-n'+2j_1(\ell_1+1), t+t'+2j_2(\ell_2+1)}
  -\gd_{n+n'+2j_1(\ell_1+1),t-t'+2j_2(\ell_2+1)}
\,,
\end{eqnarray*}
where $\gd_{zz'}$ is the free Green's function \refeq{GreenFun1}.
Substituting  \refeq{GreenFun3} yields
the \spt\ Green's function as a convolution of the two 1\dmn\
Green's functions \refeq{BGtempCatGF}
\begin{equation}
 \gd_{z z'}  =\frac{1}{2\pi}\int_{-\infty}^{+\infty}d\eta\,
              \gd_{nn'}(s/2+i\eta)  \gd_{tt'}(s/2-i\eta)
\,.
\label{DirGreenFun1}
\end{equation}

    \BG{2017-07-18, 2019-10-31}{
TO NEVER BE CONTINUED
    }

\section{Toeplitz tensors}
\label{sect:Green2d}

In refsect~{s-lattProp} we worked out the propagator in the
only in $d=1$ configuration space, and stated the result for $d>1$
after the Fourier transform diagonalization. What are the generalizations of
Toeplitz matrices to  $d>1$? They are called {\em Toeplitz tensors}.

\begin{description}

    \PCpost{2018-02-24}{
This one I think is not relevant to us:
Lim\rf{Lim05}
{\em Singular values and eigenvalues of tensors: {A} variational approach} - ``
A theory of eigenvalues, eigenvectors, singular values, and singular
vectors for tensors based on a constrained variational approach much like the
Rayleigh quotient for symmetric matrix eigenvalues. An illustration:
a multilinear generalization of the Perron-Frobenius theorem.
''
    }

    \PCpost{2018-02-24}{
Khoromskaia and Khoromskij\rf{KhoKho17}
{\em Block circulant and {Toeplitz} structures in the linearized {Hartree-Fock}
equation on finite lattices: {Tensor} approach} seems quite relevant to our project
- they work out the  $D=3$ lattice case: ``
grid-based tensor approach to solution of the elliptic eigenvalue problem for
the 3D lattice-structured systems. We consider the linearized Hartree-Fock
equation over a spatial $L_1\times L_2\times L_3$ lattice for both periodic and
non-periodic case.
In the periodic case the low-rank tensor structure in the diagonal blocks of
the Fock matrix in the Fourier space reduces the conventional 3D FFT to the
product of 1D FFTs.
''


Xie, Jin and Wei\rf{XiJiWe16}
{\em A fast algorithm for solving circulant tensor systems}: ``
Circulant tensors is a generalization of the circulant matrix. We define the
generalized circulant tensors which can be diagonalized by a Fourier matrix,
and solve the circulant tensor system by a fast FFT algorithm.
''

Cui \etal\rf{CuChLiNg15}
{\em An eigenvalue problem for even order tensors with its applications}: ``
Using the matrix unfolding of even order tensors, we can establish the
relationship between a tensor eigenvalue problem and a multilevel matrix
eigenvalue problem. We show that higher order singular values are the square
root of the eigenvalues of the product of the tensor and its conjugate
transpose, as in the matrix case. Also we study an eigenvalue problem for
Toeplitz/circulant tensors, and give the lower and upper bounds of eigenvalues
of Toeplitz tensors.
''

Rezghi and Eld{\'{e}}n\rf{Rezghi11}
{\em Diagonalization of tensors with circulant structure}: ``
A tensor of arbitrary order, which is circulant with respect to two
modes, can be diagonalized in those modes by discrete Fourier transforms. This
property can be used in the efficient solution of linear systems involving
contractive products of tensors with circulant structure. Tensors with
circulant structure occur in models with periodic boundary
conditions.
''


    }

    \PCpost{2018-02-24}{
In 2007 the N-way Toolbox, Tensor Toolbox, and Multilinear Engine were
software packages for working with tensors.

block-Toeplitz matrix

A tensor can be regarded as a multidimensional array of data.
The order of a tensor is the number of dimensions.
The dimensions of a tensor also are known as \emph{ways} or \emph{modes}.

Multilevel matrices arise in multidimensional applications.


    }


\end{description}


\section{Green's blog}
\label{sect:blog2dGreen}

\begin{description}
    \PCpost{2016-07-13}{
Cat map Green's functions are standard 'lattice propagators' for
discrete lattices, obtained by discrete Fourier transform diagonalization
of discrete Laplacian. Working through Chaos\-Book sections {\em D.3
Lattice derivatives} to {\em D.5.2 Lattice Laplacian diagonalized} might
help you understand this material.

Note: All eq. numbers refer to svn ver.~5020 of \HREF{160521Gutkin.pdf}
{160521Gutkin.pdf} and ChaosBook.org
\HREF{http://chaosbook.org/pdf.shtml} {ver.~15.7}. You can also use
\HREF{http://chaosbook.org/pdf.shtml}
{current ver.}, but the chapter numbering is different.
    }

    \PCpost{2017-02-17}{
For diffusion, a linear (symmetric,  Vivaldi) code is needed.

For {\catlatt}
\begin{enumerate}
  \item
linear code seems needed. Have not proven that.
  \item
its partition volumes have no relation to 2-tori weights
  \item
linear code pruning rules undercount 2-tori pruning rules
  \item
2-tori are intrinsic to the flow, there might exist Markov partitions
\\{\bf Boris 2017-02-17}
Markov partitions for {\catlatt}s exist, but their complexity grows
exponentially with number of cats.
\\{\bf Predrag 2017-03-04}
That is what you keep saying, but if you mean {\em finite} Markov partitions
for {\em the} {\catlatt}, even on a finite spatially periodic domain, I have
never seen it. It would require high-dimensional unstable/stable manifolds of
the fixed point at the origin to map onto each other, in order to get a
generating partition consisting of a finite number of volumes. Pretty
amazing.
\end{enumerate}
    }

\PCpost{2017-08-25} {
I have not understood this before, but the
$\R = [2\!\times\!1]$ {\brick}
\[
\Mm=\left[\begin{array}{c}
\Ssym{11} \Ssym{21}
\end{array}\right]
\]
is not just a 1D {\templatt} - the Dirichlet boundary conditions make
this nasty as well,
\[
\Mm\cup\partial\R=\left[\begin{array}{c}
\ssp_{12} \ssp_{22}   \\
\ssp_{01}\Ssym{11} \Ssym{21}\ssp_{31} \\
\ssp_{10} \ssp_{20}   \\
\end{array}\right]
\,.
\]
    }

\PCpost{2017-08-25} {
$\partial\R=\{\ssp_{1}, \ssp_{2},  \cdots \ssp_{8}\}$ is not consistent with
our notation: they live on sites, and should be labelled by index pairs
$\partial\R=\{\ssp_{z}\}$, in $\R = [2\!\times\!1]$ example as
$\partial\R=\{\ssp_{01}, \ssp_{02}, \ssp_{13},\cdots, \ssp_{10}\}$. That is
consistent with the cat map, where the corresponding {\brick} + boundary
points is correctly labelled as $\ssp_{0}\Ssym{1} \Ssym{2}\ssp_{3}$. The
crazy thing is that even with the correct notation, there is no rhyme nor
reason in the above 8 inequalities.
{\scriptsize
\begin{eqnarray*}
 0 \leq  (\ssp_{01} +\ssp_{10}-\Ssym{12})(s^2-2)+(\ssp_{13}+\ssp_{02}+\ssp_{31}+\ssp_{20}-\Ssym{22}-\Ssym{11})s +(\ssp_{23}+\ssp_{32}-\Ssym{21})2\leq\nu_s\nonumber\\
 0 \leq (\ssp_{02} +\ssp_{13}-\Ssym{22})(s^2-2)+(\ssp_{01}+\ssp_{10}+\ssp_{23}+\ssp_{32}-\Ssym{12}-\Ssym{21})s +(\ssp_{20}+\ssp_{31} -\Ssym{11} )2\leq\nu_s\nonumber\\
 0\leq   (\ssp_{20} +\ssp_{31}- \Ssym{11})(s^2-2)+(\ssp_{01}+\ssp_{10}+\ssp_{23}+\ssp_{32} -\Ssym{12}-\Ssym{21})s  +(\ssp_{02}+\ssp_{13}-\Ssym{22})2\leq\nu_s\nonumber\\
 0\leq (\ssp_{23} +\ssp_{32} -\Ssym{21})(s^2-2)+(\ssp_{13}+\ssp_{02}+\ssp_{31}+\ssp_{20} - \Ssym{22}-\Ssym{11} )s+(\ssp_{01}+\ssp_{10} -\Ssym{12})2\leq\nu_s
\end{eqnarray*}
}
    }

\BGpost{2017-08-30}
{In principle you are right, but keeping 2 indices would only make things
look terribly  ``heavy`` (without a good justification, as anyway ''there
is no rhyme nor reason``). The single index notation for the boundary
points seems to me the least evil. {\bf 2017-09-09 Predrag} not
convinced, but this is really a minor point. We follow Boris'
convention.}

    \PCpost{2017-09-09}{
Dorr\rf{Dorr70}
{\em The direct solution of the discrete {Poisson} equation on a rectangle}

Hu, Ryu and {O'Connell}\rf{HuRyCo98} {\em Analytical solution of the
generalized discrete {Poisson} equation} ``
present an analytical solution to the generalized discrete Poisson
equation (DPE), a matrix equation which has a tridiagonal matrix with fringes
having an arbitrary value for the diagonal elements.''


Many  physical  problems  require  the  numerical  solution  of  the  Poisson
equation  on  a rectangle.  In general, one uses the finite-difference
method\rf{Dorr70}, where the rectangle is  replaced  by  an $N \times k$
grid,  and  the  Poisson  equation  is  solved  in  the  finite-difference
representation.  In this way, the problem is reduced to the discrete Poisson
equation (DPE) on  an $[N\!\times\!k]$ grid,  a  matrix  equation
\(
\D \ssp = \Ssym{}
\)
having  a
tridiagonal  matrix $[k\!\times\!k]$ with  fringes, of form
\beq
\D= \left(\begin{array}{ccccccc}
M & 1 & 0 & 0 &\dots &0&0 \\
1 & M & 1 & 0 &\dots &0&0 \\
0 & 1 & M & 1  &\dots &0 & 0 \\
\vdots & \vdots &\vdots & \vdots & \ddots &\vdots &\vdots\\
0 & 0 & \dots &\dots &\dots &M & 1 \\
0 & 0 & \dots &  \dots &\dots &1 & M
        \end{array} \right )
\,,
\ee{3diagDPE}
where $M$ is a $[N\!\times\!N]$ symmetric tridiagonal matrix
\refeq{3diagToeplitz}, with constant $-s$ along the diagonal, and the
$[N\!\times\!N]$ identity matrix 1 as the off-diagonal elements.
Thus, the matrix
$\D$ consists of $[k\!\times\!k]$ submatrices of $[N\!\times\!N]$ elements.
An important special case is $s=4$, which is the matrix form for the Poisson
equation on a rectangle arising from the difference method.

They invert $\D$ in three steps:
\begin{enumerate}
  \item
By applying the results of \refref{HuCon96}, invert $\D$  into $\D^{-1}$.
This generalizes \refeq{HuCon96(10)} to a (sub)matrix formula, with $\gd_{jk}$
replaced by submatrix $\Theta_{jk}$, where $\Theta$ is an $[N\!\times\!N]$ matrix
defined by
\[
  -2\cosh\Theta = M
\]
  \item
The eigenvalues and eigenfunctions for the submatrices of the block
matrix  $\gd=\D^{-1}$ are given by \refeq{3diagToepEigs}.
  \item
Evaluate analytically each of the individual elements in the inverted matrix
$\D^{-1}$ by the Schur decomposition scheme\rf{GoVanLo96}.
\end{enumerate}
I find the procedure inelegant and cumbersome, as the two dimensions are
treated in different ways. The result is, however, a bit more symmetric
(but not written fully symmetric), written in terms of coefficients such as:
\[
  \alpha_{lm}(n)= \sqrt{\frac{2}{N+1}}
     \sinh\frac{ln\pi}{N+1}\sinh\frac{mn\pi}{N+1}
\,.
\]
In contrast, Boris formulation \refeq{GreenFun1} is symmetric.

My intuition is explained in refsect~{s-lattProp} - the $d$ translations
commute, so should compute eigenvalues for each direction
separately. Works out for periodic boundary conditions.

As a wild guess, in $d$\dmn\ the Jacobian \refeq{3diagToeplitzDet} for Dirchlet b.c.
would generalize to the product of $d$ Jacobians, one for each direction
\beq
  \det(\D_{\ell_1\times\ell_2\times\cdots\ell_d})  % = %(-1)^\ell
                 % \frac{\sinh(\ell+1){m}}{\sinh{m}}
                = U_{\ell_1}(s/2)U_{\ell_2}(s/2)\cdots U_{\ell_d}(s/2)
\,.
\ee{dDimToeplitzDet}
For example,
\beq
  \det(\D_{1\!\times\!1})
                = U_{1}(s/2)U_{1}(s/2) = s^2
\,,
\ee{Detblock1x1}
and
\beq
  \det(\D_{2\!\times\!2})
                = U_{2}(s/2)U_{2}(s/2) = (s^2 - 1)^2
\,.
\ee{Detblock2x2}
This naive guess is almost certainly wrong...

How does one get cosh's and sinh's in the circulant matrix case?
    }


    \PCpost{2017-09-09}{
\phantomsection\label{2017-09-09post}
A few more links to digest:

\HREF{https://math.stackexchange.com/questions/1829043/eigenvalues-of-periodic-lattice-laplacian}
{\em Eigenvalues of periodic lattice Laplacian?}
uses the Kronecker product, and Harshaw gives sensible, symmetric
eigenvalues for a doubly-periodic torus, something like
\beq
\lambda^{[\speriod{1}\times\period{2}]}_{jk}
  = - {\mu}^2 - 2\cos\frac{j\pi}{\speriod{1}} - 2\cos\frac{k\pi}{\period{2}}
\,,
\ee{Harshaw16a}
where,
\(
\,,\quad
  0\leq j\leq\speriod{1}-1\,,\;
  0\leq k\leq\period{2}-2\,,
\) and $d=2$. Their problem is the usual diffusive Laplacian on a
square lattice, has no $s$ term, so this is still only a guess.

Andreas Wipf\rf{Wipf13}
{\em Statistical Approach to Quantum Field Theory: An Introduction}
\CBlibrary{Wipf13}.

\arXiv{math/0010135} {\em Integrable Lattices: Random Matrices and Random Permutations}

\arXiv{1702.00339} {\em Block circulant and Toeplitz structures in the linearized
Hartree-Fock equation on finite lattices:  tensor approach}

    }

    \PCpost{2017-09-08}{
Giles and Thorn\rf{GilTho77}
{\em Lattice approach to string theory}.
The Giles-Thorn (GT) discretization of the worldsheet
begins with a representation of the free closed or open
string propagator as a lightcone worldsheet path integral
defined on a lattice.

The sequel
Papathanasiou and Thorn\rf{PapTho13}
{\em Worldsheet propagator on the lightcone worldsheet lattice}
give  in Appendix~B 2D lattice Neumann open string, Dirichlet open string, and
closed string propagators.

{\em Discrete {Green's} functions}
are explained, for example, by Chung and Yau\rf{ChuYau00} who give
explicitly, in their Theorem~6, a 2\dmn\ lattice Green's function for a
rectangular
% $\R^{[\ell_1\times\ell_2]}$ region
$R^{[\ell_1\times\ell_2]}$. I do not understand the paper - in any case,
I see no determinants in it. This paper is cited over 100 times, maybe
there is a better answer in that list.

%\bibitem{DysonOscillators}
%	F.~J. Dyson.
%	\newblock The dynamics of a disordered linear chain.
%	\newblock {\em Physical Review}, 92(6):1331--1338, 1953.
    }

    \PCpost{2017-09-11}{
Bhat and Osting\rf{BhaOst10} {\em Diffraction on the two-dimensional square
lattice} write: The lattice Green's function is quite well
known\rf{KatIna71,Economou06}.

Katsura\rf{KMIHA71}
{\em Lattice {Green's} function. {Introduction}}:
The Helmholtz equation for the wavefunction $\psi(r)$ in the continuous space
is given by
\beq
\left(
\frac{1}{2}\Delta+E
\right)\psi = 0
\ee{Katsura1}
The Green's function $g(E,r)$ is the solution of
\beq
\left(
\frac{1}{2}\Delta+E
\right)g = \delta(r)
\ee{Katsura2}
The real part of the square lattice Green's function \refeq{GreenFun1} is odd
or even function of $s$, and the imaginary part is even or odd function of
$s$, if the sum of $n$ and $t$ is even or odd, respectively.

Morita and Horiguchi\rf{MorHor71} {\em Calculation of the lattice {Green's}
function for the bcc, fcc, and rectangular lattices}:
see the appendix {\em The lattice {Green's} functions for the rectangular
lattice} (includes the square lattice as a special case). They integrate
\refeq{GreenFun1} and express it as the complete elliptic integral of the
first kind \refeq{Cserti00(38)}.

Katsura, Inawashiro and Abe\rf{KaInAb71} {\em Lattice {Green's} function for
the simple cubic lattice in terms of a {Mellin-Barnes} type integral}

Horiguchi\rf{Horiguchi71}
{\em Lattice {Green's} function for the simple cubic lattice} - GaTech
does not have  online access to it.

Horiguchi and Morita\rf{HorMor75}
{\em Note on the lattice {Green's} function for the simple cubic lattice}: ``
A simple recurrence relation connecting the lattice Green's function at (l,m
n) and the first derivatives of the lattice Green's function at
$(l\pm1,m,n)$, is presented for the simple cubic lattice. By making use of
that recurrence relation, the lattice Green's functions at (2,0,0) and
(3,0,0) are obtained in closed forms, which contain a sum of products of the
complete elliptic integrals of the first and the second kind,
see \refeq{Cserti00(38)}.
''

Asad\rf{Asad07} {\em Differential equation approach for one- and
two-dimensional lattice {Green's} function} seems a continuation of
\refref{HorMor75}: ``
A first-order differential equation of Green's function, at the origin G(0),
for the one-dimensional lattice is derived by simple recurrence relation.
Green's function at site (m) is then calculated in terms of G(0). A simple
recurrence relation connecting the lattice Green's function at the site (m,n)
and the first derivative of the lattice Green's function at the site
$(m\pm1,n)$ is presented for the two-dimensional lattice, a differential
equation of second order in G(0, 0) is obtained. By making use of the latter
recurrence relation, lattice Green's function at an arbitrary site is
obtained in closed form.
''
    }

    \BGpost{2017-09-11}{
Some caution on Green's functions: In 1D everything is explicit and simple.
The real problem is $2D$. For the paper we need two facts --  positivity of
its elements, and exponential decay (both for Dirichlet boundary conditions).
I was unable to extract them from the literature (which is bizarre), but
checked numerically. Proofs are  still lacking, but should be within reach.
    }

    \PCpost{2017-09-20}{
Continued feline misery. From the periodic orbit theory point of view, it is
insane to work with finite lattice {\brick}s with Dirichlet boundary conditions.
The theory demands periodic boundary conditions. They preserve translational
invariance which makes Green's matrices trivially diagonizable by discrete
Fourier transforms. Now that Boris is such a mensch that he can do it, I am
writing up a pedagogical Dirichlet/periodic b.c.'s Green's matrices appendix
to \refref{GHJSC16} (or per chance even a section of the paper proper, as
this is no afterthought - this is the central point of the paper), an
appendix whose ultimate goal is to show that the matrix elements are decaying
exponentially as
\beq
\D_{zz'} \approx \e^{-\lambda  |z-z'|^d}
\,,
\ee{expDecayCatLatt}
\ie, in our humble $d=2$ example as $\exp(-\lambda |z-z'|^2)$. If the
coauthors were to understand or (gasp!) contribute to the write up, we would
be in cat heaven.

So far, still writing up the $d=1$ {\templatt} example of
\refsect{sect:Green1d}, but the determinant of the Helmholtz operator for any
finite $d=2$ rectangular lattice region of \refsect{sect:Green2d} should play
out the same way.

To Matt and Andy:
This goes lock, stock and barrel into the continuum field
theories, such as Kuramoto-Sivashinsky, with the Euclidian metric
in \refeq{expDecayCatLatt} replaced by the (still to be thought through)
correct Kuramoto-Sivashinsky spacetime metric.
    }

    \PCpost{2017-10-18}{
Glaser\rf{Glaser70} {\em Numerical solution of waveguide scattering problems
by finite-difference {Green's} functions} computes a 2\dmn\ Green's function
with boundary conditions on arbitrary shape approximated by a discrete boundary:
``A finite-difference Green's function method for solving time-harmonic wave
guide scattering problems involving metallic obstacles of finite size is
applied to the two-dimensional problem of a TE10 mode impinging on
cylindrical metallic posts of arbitrary shape in a rectangular waveguide.''
}

    \PCpost{2017-10-19}{
de la Llave\rf{dlLlave00} {\em Variational methods for quasiperiodic solutions
of partial differential equations}
has a pedagogical  discussion of the discrete lattices gradient flows.
    }

\item[2017-09-11 Predrag]
Katsura and Inawashiro\rf{KatIna71} {\em Lattice {Green's} functions for
the rectangular and the square lattices at arbitrary points}. They start
with product of two Bessel functions \refeq{GreenFun4}, then go
hypergeometric, or $K(u)$ complete elliptic. In the appendix they study
lattice Green's function of the linear lattice (\ie, $d=1$ lattice), and
relate it to Chebyshev $T_m(u)$ and in turn to the hypergeometric ${}_2
F{}_1$.

\item[2019-11-04 Predrag]
Doyle and Snell\rf{DoySne00} \arXiv{math/0001057} present the connection
between random walks and electric networks.


\item[2020-05-09 Predrag]
Sunada\rf{Sunada13} {\em Topological Crystallography}
\CBlibrary{Sunada13} Chap.~9 is all about random walks on lattices.

\item[2020-05-10 Predrag]
                                                        \toCB
Some general graph-theory definitions, from different sources,
will eventually be all in ChaosBook \emph{appendMarkov.tex} :

% Chinta, Jorgenson and Karlsson\rf{ChJoKa14}
Many follow the definitions in
Serre\rf{Serre80} and Stark and Terras\rf{StaTer96}.

Let $G=(V,E)$ be a connected {\it non-directed} graph, with $V$ the set
of $|V|$ vertices or nodes (assume that there are no 1-degree vertices),
$E$ the set of $|E|$ unoriented edges (possibly multiple edges and
1-loops) labeled $e_{1}, \cdots, e_{|E|}$.

The \emph{adjacency  matrix} for an undirected graph  with $n$ nodes is
an $[n\!\times\!n]$ matrix \refeq{adj_matTerras} with (i,j)-th  entry
specifying  the number  of  non-directed  edges from  node i to j with
i-th  diagonal entry  being  twice  the  number  of self-adjoining  loops
on i-th node.

A graph is \emph{finite} if it has a finite number of and  edges. It is
\emph{connected} if every  node  can  be  reached by  traversing a path.

A \emph{rooted graph} is a pair $(G, v)$ , where $G$ is a graph and
$v\in V$ is a vertex of $G$, called the root.

A graph is \emph{simple} if it has no  loops, \ie,  no  edges  of the
form  $(u,u)$ $u\in V$ and  there  is  at most  a  single  edge between
any two vertices.

A graph is \emph{bi-partite} if its vertices can be partitioned into two
disjoint sets U and W such that no vertex in U is adjacent to any other
vertex in U and likewise for W; the graph has edges only between ``U''
and ``W'' vertices.

In order to define a closed path in a non-directed graph orient the
edges in an arbitrary but fixed way.
Oriented edge $e=(u,v)\in E(G)$ joins two vertices, the origin
$u=o(e)$
to the tip $v=t(e)$.

The vertices $o(e)$ and $t(e)$ are the \emph{extremities} of the edge
$E$. Two vertices are \emph{adjacent} if they are extremities of an edge.

The \emph{degree} of a vertex $v$ is
$\mbox{deg} v = \mbox{Card} \{e \in E_v : o(e) = v\}$.
A graph is $d$-regular if each vertex has degree $d$.

The in-degree (respectively out-degree) of any vertex of a directed graph is
the number of in-coming (respectively out-going) edges.
For a \emph{directed regular} graph all vertices have equal in-degrees
and out-degrees.

A  graph is \emph{vertex transitive} if there is a group of automorphisms
which is transitive on the vertices. Such a graph is \emph{regular}.

In the
physics literature regular trees are called Bethe lattices.

Denote by $\e^{-1}=(v,u)$ the inverse of $e=(u,v)$,
with the origin $v$ and the tip $u$.

Let $G'$ be the graph with $2|E|$ oriented
edges built from such oriented graph $G$ by adding
the opposing oriented edges $e_{|E|+1}=(e_{1})^{-1}$,
...,$e_{2 |E|}=(e_{|E|})^{-1}$.

If $e_{i}$ belongs to an oriented loop,
$e_{i+|E|}=(e_{i})^{-1}$ belongs to oriented loop going
through the same pair of vertices.

A path $P=(e_1,\cdots,e_n)$ has a backtracking if $e_{i+1}^{-1}=e_i$.
The path has a \emph{tail} if $e_0 = e_{n-1}^{-1}$.

The \emph{inverse cycle} of a cycle $C=(e_1,\cdots,e_n)$ is the cycle
$C^{-1}=(e_n^{-1},\cdots,e_1^{-1})$.

The cycle $C$ is called reduced if \(C^2\) has no backtrack, and prime if
it can not be expressed as \(C=D^f\) for any cycle D and \(f\ge 2\).

A cycle $C$ is prime if it is not a repeat of a strictly smaller cycle.

Cycles $C_1=(e_1,\cdots,e_n)$ and $C_2=(f_1,\cdots,f_n)$ are called
\emph{equivalent} if there exists k such that $f_j=e_j+k$ for all j.
Let $[C]$ be the equivalence class which contains a cycle $C$.

For a cycle $C$, the equivalence class $[C]$  is the set of cyclic
permutations of $C$ , \ie, cycles are equivalent up to choice of the
initial/terminal vertex.

A `prime cycle' (`\orbit') is non-backtracking, tailless and not a $r$-multiple cycle.

A geodesic in a graph is a path without back-tracking, consistent with
Riemannian geometry where a geodesic is a path which is  locally distance
minimizing. A closed geodesic is a closed path without back-tracking or
tails.


A \emph{tree} is a connected nonempty graph without geodesic loops.

In Riemannian geometry geodesics are locally distance minimizing paths
and the difference between a \emph{geodesic loop} and a \emph{closed
geodesic} is that the latter is required to be differentiable also at the
starting/ending point.

A path is closed if $e_0=e_n$. A geodesic is a path without backtracking.
A geodesic loop (or circuit in Serre's terminology) is a closed path that
is a geodesic. A closed geodesic is a closed path with no tail and
without backtracking.

The path of length zero counts as a closed geodesic and, therefore, is a
geodesic loop. Additionally, every closed path with one edge counts as a
closed geodesic. Any length two geodesic loop is also a closed geodesic,
but the closed path $e\,e^{-1}$ is neither.

A \emph{prime} geodesic is an equivalence class of closed geodesics $[C]$
(where the equivalence class is forgetting the starting point) which is
primitive in the sense that it is not a power of another closed geodesic.
The latter means by definition that there is no closed geodesic d and
integer $n > 1$ such that $[C] = \left[d^n\right]$, which says in words
that c is not just a geodesic that traverses another one n number of
times.

In graph theory the names for ``closed geodesics'' or ``geodesic loops'',
range from circuits, loops etc, to closed paths without backtracking and
no tails.

In terms of a graph $G = (V,E)$, a random walk is a stochastic process
associated with a positive-valued function $p$ on $E$ satisfying
\[
\sum_{e\in E_v}
p(e) = 1
\,.
\]
$p(e)$ is the transition probability that a random walker
at $o(e)$ moves to $t(e)$ along the edge $e$.
The transition operator $P : C(V) \to C(V)$,
$C(V)$ the space of functions on $V$, is defined by
\[
Pf(x) = \sum_{e\in E_v} p(e) f(t(e))
\,.
\]
The n-step transition probability $p(n,x,y)$ is the probability that
after the $n$-steps a random walker at the initial site $x$ is found at
$y$,
\[
\left(P^n\right)f(x) = \sum_{y\in V} p(n,x,y) f(y)
\,.
\]
The \emph{simple random walk} on $G=(V,E)$  is the walk such that the
probabilities moving along out-going edges from a vertex are the same,
with the transition probability $p(e)=1/\mbox{deg}\,o(e)$.

The operator $P-I$ is the discrete Laplacian associated
with the weight functions $m_V(v) = \mbox{deg}\,v$, $m_E=1$,
\beq
\left((P^n-I)f\right)(v) = \frac{1}{\mbox{deg}\,v}\sum_{e\in E_v}
        \left[f(t(e))-f(o(e))\right]
\,.
\ee{graphLapl}
$P_v-I$ is the discrete analogue of the \emph{twisted
Laplacian}\rf{Sunada89}
\PC{2020-05-05}{Looked at Sunada\rf{Sunada89}, but still not sure what is
                a `twisted' Laplacian.}
\PC{2020-05-13}{Why ${1}/{\mbox{deg}\,v}$ in \refeq{graphLapl}?}

Let $\Lambda$ be a Bravais lattice. Then $P$ is $\Lambda$-equivariant,
and is related to the transition operator $P_0$ associated with the
simple random walk on over a finite graph $G_0=(V_0,E_0)$ as
\[
P( f \circ \omega) = \left(P_0( f )\right) \circ \omega
\,,
\]
where $f$ is an arbitrary function on $V_0$, and
$\omega : G \to G_0$ is the covering map.

\item[2020-05-11 Predrag]
Bharatram Rangarajan
{\em A combinatorial proof of Bass's determinant formula for the zeta
function of regular graphs}, \arXiv{1706.00851}:

For an integer $d \geq 2$, let $G=(V,E)$ be a finite $d$-regular undirected graph with adjacency matrix $A$. A \emph{walk} on the graph $G$ is a sequence $v_0v_1\dots v_{k}$ where $v_0,v_1,\dots,v_k$ are (not necessarily distinct) vertices in $V$, and for every $0 \leq i \leq k-1$, $(v_i,v_{i+1}) \in E$. The vertex $v_0$ is referred to as the \emph{root} (or origin) of the above walk, $v_k$ is the terminus of the walk, and the walk is said to have length $k$.\\
It is often useful to equivalently define a walk as a sequence of directed or oriented edges. Associate each edge $e=(v,w) \in E$ with two directed edges (or rays) denoted
$$\vec{e}=(v \to w)$$
$$\vec{e}^{-1} = (w \to v)$$
Note that the origin $org(\vec{e})$ is the vertex $v$ and its terminus $ter(\vec{e})$ is the vertex $w$. Similarly, the origin $org(\vec{e}^{-1})$ is the vertex $w$ and its terminus $ter(\vec{e})$ is the vertex $v$. Let $\vec{E}$ denote the set of $m=nd$ directed edges of $G$. So a walk of length $k$ can equivalently be described as a sequence $\vec{e}_1\vec{e}_2\dots\vec{e}_k$ of $k$ (not necessarily distinct) oriented edges in $\vec{E}$ such that for every $1 \leq i \leq k-1$,
$$ter(\vec{e}_i) = org(\vec{e}_{i+1})$$
This is a walk that starts at $org(\vec{e}_1)$ and ends at $ter(\vec{e}_k)$.\\
It is easy to show that for any $k \in \integers$, the number of walks of length $k$ between vertices $u,v \in V$ is exactly $(A^k)_{u,v}$. In particular, the total number of rooted cycles of length $k$ in $G$ is exactly
$$\Tr(A^k)$$


A \emph{non-backtracking walk} of length $k$ from $v_0 \in V$ to $v_k \in
V$ is a walk $v_0v_1\dots v_k$ such that for every $1 \leq i \leq k-1$,
$$v_{i-1} \neq v_{i+1}$$
Equivalently, a non-backtracking walk of length $k$ from $v \in V$ to $w
\in V$ is a walk $\vec{e}_1\vec{e}_2\dots\vec{e}_k$ such that
$org(\vec{e}_1)=v$, $ter(\vec{e}_k)=w$ and for every $1 \leq i \leq k-1$,
$$\vec{e}_{k+1} \neq \vec{e}^{-1}_{k}$$
Non-backtracking random walks on graphs have been studied in the context
of mixing time [cite {alon}], cut-offs [cite {peres}], and exhibit more
useful statistical properties than ordinary random walks. In
[cite {peres}], the authors obtain further interesting results on the
eigendecomposition of the Hashimoto matrix $H$.

A rooted, non-backtracking cycle of length $k$ with root $v$ is a
non-backtracking walk $v,v_1,v_2,\dots,v_{k-1},v$ with the additional
boundary constraint that
$$v_1 \neq v_{k-1}$$

Let $\mathcal{C}$ denote the set of all rooted, non-backtracking, closed walks in $G$, and for $C \in \mathcal{C}$, let $|C|$ denote the length of the walk $C$. There are two elementary constructions we can carry out to generate more elements of $\mathcal{C}$ from a given cycle $C$:
\begin{itemize}
\item \emph{Powering}: Given a rooted, non-backtracking closed walk $C \in \mathcal{C}$ of length $k$ of the form
$$C=\vec{e}_1\vec{e}_2\dots\vec{e}_k$$
then for $m \geq 1$ define a power
$$C^m = \underbrace{\vec{e}_1\dots\vec{e}_k \vec{e}_1\dots\vec{e}_k \dots \vec{e}_1\dots\vec{e}_k}_{\text{m times}}$$
which is a concatenation of the string of edges corresponding to the walk $C$ with itself $m$ times. Note that $C^m$ is also a rooted, non-backtracking closed walk in $G$ of length $mk$. Essentially, $C^m$ represents the walk obtained by repeating or winding the walk $C$ $m$ times. Also note that $C$ and $C^m$ are both rooted at the same vertex.
\item \emph{Cycle class}: Given a rooted, non-backtracking closed walk $C \in \mathcal{C}$ of length $k$ of the form
$$C=\vec{e}_1\vec{e}_2\dots\vec{e}_k$$
we can form another walk
$$C^{(2)}=\vec{e}_2 \vec{e}_3 \dots \vec{e}_k \vec{e}_1$$
which is also a rooted, non-backtracking closed walk in $G$ of length $k$, but now rooted at the origin of the directed edge $\vec{e}_2$ (or the terminus of $\vec{e}_1$). More generally, for $1 \leq j \leq k$, define
$$C^{(j)} = \vec{e}_j \vec{e}_{j+1} \dots \vec{e}_k \vec{e}_1 \vec{e}_2 \dots \vec{e}_{j-1}$$
which is a cyclic permutation of the walk $C$ obtained by choosing a different root. So given a walk $C \in \mathcal{C}$ of length $k$, we get $k-1$ additional walks in $\mathcal{C}$ of length $k$ for free this way. In fact, this defines an equivalence class $\sim$ on $\mathcal{C}$, and the set
$$[C]=\{C^{(1)},C^{(2)},\dots,C^{(k)} \}$$
is called the equivalence class of $C$. An element $[C] \in \mathcal{C}/\sim$ represents a non-backtracking closed walk modulo a choice of root.
\end{itemize}


\item[2019-10-31 Predrag] Guttmann\rf{Guttmann10}
{\em Lattice {Green's} functions in all dimensions} starts the way I
understand, with random walks on lattices
(\HREF{http://chaosbook.org/FieldTheory/QMlectures/lectQM.pdf\#section.1.1}
{Wanderings of a drunken snail}), apparently discussed eruditely by
Hughes\rf{Hughes95} and also used in the calculation of the effective
resistance of resistor networks\rf{Cserti00}, but then quickly leads to
an amazing range of deep mathematics which we can safely ignore (though
not some of the references).

``
for a translationally invariant walk on a $d$\dmn\ periodic
Bravais lattice, a natural question to ask is the probability that a
walker starting at the origin of a lattice will be at position $z$ after
n steps. The probability-generating function is known as the lattice
Green's function
\(
\gd_{z,0}
\,.
\)
[...] the \emph{structure function} of the lattice and is given by the
discrete Fourier transform of the individual step probabilities. For
example, for the $d$\dmn\ hypercubic lattice, the structure function is
\[
\lambda(k) =
\frac{1}{d}
(\cos k_1 + \cos k_2 + \cdots + \cos k_d )
\,.
\]
Harshaw \refeq{Harshaw16a} seem to be in the same spirit.

[...] The probability of returning to the origin is
\[
1-1/\gd_{0,0}
\,.
\]
Since $\gd_{0,0}$ diverges for two-dimensional lattices, the probability
of returning to the origin by a random walker in two dimensions is
certain.
[...]
For the infinite square lattice, the result is remarkably simple:
\[
\gd_{z,0}(u) = \frac{2}{\pi}K(u)
\]
where $K(u)$ is the complete elliptic integral of the first kind
\refeq{Cserti00(38)},
with hypergeometric representation
\[
  K(u) = \frac{\pi}{2}\,{}_2 F{}_1\left(\frac{1}{2},\frac{1}{2};1;u\right)
\]
For the square lattice, we can also use the equivalent structure function
\[
\lambda(k) =
\cos k_1 \, \cos k_2
\,,
\]
demonstrating that structure functions for a given lattice are not unique.
[...]
In $d=3$ the result for the simple cubic case is a saga in itself.
[...]
''

\item[2020-02-09 Predrag]
Chen\rf{ChenM87} {\em On the solution of circulant linear systems}:
In the case where multidimensional problems are concerned, the matrices
of coefficients of the resulting linear systems are block circulant
matrices. After some transformations and permutations we are led to a
block diagonal matrix with circulant blocks on the diagonal. This reduces
the problem to the solution of n circulant linear systems, which may be
performed in parallel. An important example is the finite difference
approximate solution of elliptic equations over a rectangle with periodic
boundary conditions\rf{BuGoNi70,Wood71}.

Sect.~4:
A block matrix is a matrix defined by smaller matrices, called blocks.
A block matrix $M$, where each of the blocks $M_i$  it self an
circulant, is called block circulant with circulant blocks.
He first extracts eigenvalues of circulant blocks, then inserts them into the
large matrix.

It is well known\rf{BuGoNi70} that the approximation of Poisson's
equation on a rectangle subject to periodic boundary conditions in both
directions by the standard five-term difference scheme on a uniform mesh
results in the block circulant linear system.

He also solves biharmonic (Laplacian squared) equation with
the standard 13-term difference approximation.

\item[2020-02-16 Predrag] An example computed for\\
\emph{CL18.tex}, using
\emph{siminos/mathematica/Tensors.nb}
\renewcommand\speriod[1]{{\ensuremath{L_{#1}}}}  %continuous spatial period
\renewcommand\period[1]{{\ensuremath{T_{#1}}}}  %continuous time period


Block circulant with circulant blocks\rf{BuGoNi70,ChenM87}
$\jMorb_{[4\!\times\!2]}=$
\beq
%\jMorb_{[4\!\times\!2]} =
\left(
\begin{array}{cccc}
 \left(
\begin{array}{cc}
 -2 s & 2 \\
 2 & -2 s \\
\end{array}
\right) & \left(
\begin{array}{cc}
 1 & 0 \\
 0 & 1 \\
\end{array}
\right) & \left(
\begin{array}{cc}
 0 & 0 \\
 0 & 0 \\
\end{array}
\right) & \left(
\begin{array}{cc}
 1 & 0 \\
 0 & 1 \\
\end{array}
\right) \\
 \left(
\begin{array}{cc}
 1 & 0 \\
 0 & 1 \\
\end{array}
\right) & \left(
\begin{array}{cc}
 -2 s & 2 \\
 2 & -2 s \\
\end{array}
\right) & \left(
\begin{array}{cc}
 1 & 0 \\
 0 & 1 \\
\end{array}
\right) & \left(
\begin{array}{cc}
 0 & 0 \\
 0 & 0 \\
\end{array}
\right) \\
 \left(
\begin{array}{cc}
 0 & 0 \\
 0 & 0 \\
\end{array}
\right) & \left(
\begin{array}{cc}
 1 & 0 \\
 0 & 1 \\
\end{array}
\right) & \left(
\begin{array}{cc}
 -2 s & 2 \\
 2 & -2 s \\
\end{array}
\right) & \left(
\begin{array}{cc}
 1 & 0 \\
 0 & 1 \\
\end{array}
\right) \\
 \left(
\begin{array}{cc}
 1 & 0 \\
 0 & 1 \\
\end{array}
\right) & \left(
\begin{array}{cc}
 0 & 0 \\
 0 & 0 \\
\end{array}
\right) & \left(
\begin{array}{cc}
 1 & 0 \\
 0 & 1 \\
\end{array}
\right) & \left(
\begin{array}{cc}
 -2 s & 2 \\
 2 & -2 s \\
\end{array}
\right) \\
\end{array}
\right)
\ee{4times2blockMat1}
is of $[\speriod{}\!\times\!\speriod{}]$ block form, $\speriod{}=4$,
with $[\period{}\!\times\!\period{}]$ blocks, $\period{}=2$.
\renewcommand\speriod[1]{{\ensuremath{\ell_{#1}}}}  %continuous spatial period
\renewcommand\period[1]{{\ensuremath{\ell_{#1}}}}  %continuous time period

\end{description}
