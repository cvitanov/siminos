% siminos/gudorf/thesis/chapter/intro.tex
% $Author: predrag $ $Date: 2020-05-25 15:18:45 -0400 (Mon, 25 May 2020) $

%\section{Introduction}
%\label{sect:intro}
% Predrag                                           12 January 2016

%%%%%% an example for Matt - illustrates use of \edit for REFEREE resubmissions
\edit{
Recent experimental and theoretical advances\rf{science04}
support a dynamical vision of turbulence:
For any finite  spatial resolution,
a turbulent flow follows approximately for a finite time
a pattern belonging to a
{ finite alphabet}
of admissible patterns.
The long term dynamics is
a {walk through the space of these unstable patterns}.
The question is how to characterize and classify such patterns?
} %end \edit


Chaotic or turbulent processes categorize one of the
few outstanding problems to be solved in classical physics.
While deterministic, the complexity of the problem
can be categorized by infrequent or lack of analytic results.
It is often necessary to rely on models which capture the
important quantitative properties and behavior of the underlying
process. These models often take form as nonlinear partial
differential equations which are hyperbolically unstable.
The systems
whose spatial correlations decay sufficiently fast, and the
attractor dimension and number of positive Lyapunov exponents
diverges with system size are said\rf{HNZks86,man90b,cross93}
to be extensive, `spatio-temporally chaotic' or `weakly
turbulent.'
The Lyapunov exponents or equivalently the exponential instabilities
they quantify prevent prediction of future behavior outside a
finite time interval.
This behavior is so peculiar that it has permeated into popular culture,
where it is known as the butterfly effect. This behavior poses a serious
challenge which has effects everything from weather prediction to
air travel. While there is no specific reason other than the difficulty
for why this problem remains unsolved, the intricacies of turbulence
are typically swept under the rug of ``good enough'' models
which allow for suboptimal but sufficient engineering solutions.
The lack of forward progress motivates us to approach turbulence with a new
perspective, one that treats all continuous dimensions equally.

\MNG{2020-01-20}{ [Introduction] } % Version 2
The natural world is comprised of many different complex
processes and behaviors. The vast majority of these processes
are approximated by models which capture the quantitative
properties of the complex properties.
There are many instances, however, where
the model takes the form of a nonlinear partial differential
equation, where there are typically very few if any
analytic results. The example that we are concerned with
is nature of fluid turbulence,
one of the few yet unsolved problems in classical physics.
The Navier-Stokes equations and its modifications represent
the unanimously accepted model for fluid flows.
These equations pose many challenges because they are both
chaotic and nonlinear. The prediction of future behavior
is theoretically impossible outside of a finite time window.
This is a serious problem as turbulence
is ubiquitous in the natural world in physical systems where
liquids or gases are present. The intricacies of turbulence
are typically swept under the rug of ``good enough'' models
which allow for suboptimal but sufficient engineering solutions.
There is a severe lack in the understanding and theory of turbulence.
The substantial computational results have all occurred on
very small computational domains, also known as minimal cells. % ref
The combination of minimal cells with periodic orbit theory
shed light on the geometry of the state space of the Navier-Stokes
equations. Very important solutions denoted as ``exact coherent structures'' (ECS)
are the crux of this work\rf{W01, WK04}.
The notion of ECS came about by considering fluid flow
as a traversal of an infinite dimensional state space, here after referred
to as the ``dynamical systems formulation''.
In this infinite dimensional state space, the time invariant sets
which are topological invariants; quantities that remain
unchanged regardless of the representation of the problem. In addition,
their cycle multipliers; eigenvalues from linear stability
analysis are also metric invariants\rf{DasBuch}.
It is their unstable and stable manifolds which shape the geometry of
state space and dictate the dynamics.
% Need to actually describe the work that has been done....
There was a lot of good work done on these minimal cells but
it is impossible to extend their successes to large
domains let alone infinite ones. There are many reasons
for this but one of the deadliest reasons is the
extrinsic growth of unstable dimensions. This impossibility
is evidenced by the lack of a fundamental theory of turbulence.
It is our belief that a new approach is necessary in order
to make progress. We propose that this new way forward is
to start from scratch and create a new \spt\ theory.
Here we visualize
turbulence not as a sequence of
spatial snapshots in turbulent evolution,
but as a {\spt} pattern, in which to each
spacetime point we assign a field whose value is the velocity field
at that spatial position and time instant.

\MNG{2020-01-20}{ [Revolution] WHY?} %Version 2
% Why it was always going to fail.
% Infinite space-time explained by shadowing.
% What is wrong in the old formulation & how it is corrected
% The reason for the new why the new is important.

Conventional computational methods
are fated to fail in the face of
infinite (or even large) space-time. The initial value
problem has reached its natural conclusion and
the philosophy must be redone from scratch. While
others might argue that there is still work to be done
but the number of unstable dimensions will only increases with
system size, not to mention the exponential nature of
the instabilities. The alternative approach that
is presented here is to treat space and time as equals
in true \spt\ fashion. This seems impossible at first;
if the complexity grows exponentially in the limit of
infinite space and time separately, what hope is there
for space-time? The problem becomes tractable when viewed
through the lens of \spt\ shadowing.
% The reasons why it will work
By their nature
\twots\ are global (infinite) solutions due to their space-time periodicity.
Our hypothesis is that infinite space-time can be described
as an infinite collection of shadowing of \twots. Going even further, it is
not only the infinite ergodic trajectory which is shadowed locally by \twots;
larger \twots\ can also be described by the shadowing of smaller \twots. \twoTs\
can be subdivided until the ``atoms'' of space-time are extracted.
We shall refer to these ``indivisible'' \twots\ as \textit{fundamental tiles}.
In this context, ``fundamental'' is a reference to the fundamental physical
behaviors that tiles (typically) represent. In addition to the decomposition
of \twots\ into tiles, the reverse is also true:
finding and enumerating all tiles enables the construction
of the general space-time solution.
This is an incredibly powerful
tool whose importance will be asserted frequently and is the basis for the
entire \spt\ theory. The same can be said of periodic orbits, so what gives?
The trick hidden behind these statements is that the number of fundamental
tiles is not only finite but incredibly small; as of now there are only three
fundamental tiles. To be more precise; these tiles exist in
continuous families. It is these families that contain
the continuous deformations tiles, which helps explain the differences
in appearance between shadowing events.
By definition shadowing is not the exact realization of a \twot; it is a ``fuzzy window'' which
represents a local region of space-time that is in the proximity of
the \twot\ in question (in some norm). As the size of the shadowed \twot\
increases, so does the accuracy of the shadowing region. that is, away from
the boundary, the shadowing becomes exponentially more accurate.
As a testing ground for this new approach, we work with the \KSe,
a partial differential equation whose space-time is two dimensional.
The reason for the use of this equation is not just the reduction
of computational complexity. The two
dimensional space-time of the \KSe\ is far easier to visualize than the four
dimensional space-time of the Navier-Stokes equations.
This visualization makes the arguments more
understandable and compelling. A foreseeable critique is
that the \KSe\ is too simple of a playground; the methods developed
in this setting would not work in the Navier-Stokes setting.
The efficacy and potency of the \spt\ formulation,
however, is a great indication that the results can generalize
to higher dimensions.
This is a very attractive proposition; there have been many attempts to
find the fundamental structures necessary for the reproduction
of turbulence in the Navier-Stokes equations.
It is possible that the proper structures have already been determined but they
have not been utilized properly; that is, they have not been used in a \spt\
formulation.

The \spt\ theory is seemingly the only way forward for
the description of turbulence; but if it the computations
are not practical or tractable then the theory is dead in
the water. Fortunately, there are also many advantages in the
\spt\ implementation. This is encouraging and perhaps
a sign that the \spt\ formulation is indeed on the correct track.
The best manner in which to display these advantages
is to contrast the capabilities with the capabilities of
conventional methods.
% Intro to the new possibilities/capabilities.
In fact, this attempt to overthrow the status quo includes multiple techniques
and methods that have not yet been witnessed in the literature.
The novelty of these methods result in newfound capabilities, which in turn allow for
new analyses. The utility and important properties of these methods
will be detailed later but we provide a preview here.
% The incorrect choices of the temporal problem.
Conventional methods treat spatial dimensions
as finite and fixed while time is treated as infinite.
This is likely motivated by the finite nature of experiments,
which is ultimately how computations are validated.
This intuitive assumption is actually a very unnatural one
in the context of state space. The fundamental reason
for this is that it disregards
the translational invariance of the equations. This notion
must be reconsidered going forward as it is a very strict constraint
on the space of solutions and on the study of turbulence in general.
Finite spatial dimensions of course have practical import, but
these specific constraints should only be imposed after the
study of infinite space-time, as they represent special
cases of the general equations. The \spt\ formulation handles
this properly by treating all continuous dimensions as equal
such that all invariant symmetries are respected.
% The period AND domain size will be variables; the difficulty therein.
What are the differences and advantages of this?
The first key difference is that the governing equation
dictates the \spt\ domain size in an unsupervised
fashion; the decision of what specific domain size
to study is no longer present in the discussion.
This is another manner in which
time and space are being treated as equals; the parameters $(L,T)$
that determine the size of the \spt\ domain are both allowed to vary.
The values of these parameters
are determined by the requirement that the equations
must be satisfied locally at every lattice site.
This small detail, allowing the domain size $L$ to vary,
is not as trivial as it seems. At present it has not been seen in
the dynamical systems literature. The variation of the period $T$ is
common, however. The likely culprit behind this different treatment
is likely a result of the equations themselves. This difficulty
is especially evident in the \KSe, whose spatial derivative terms
are of higher order than the first order time derivative, but also
there is a spatial derivative present in the nonlinear component.
%
The next benefit is not due to the inclusion of new methods but
rather the exclusion of old methods. Time integration and
recurrence functions based on pairwise distance have long been used in combination
to find initial conditions. % schatz/grigoriev, kerswell, viswanath.
In the high dimensional limit, both
of these components are time consuming. This is yet another
component of the dynamical systems formulation that gets worse
as spatial sizes increase. There are two detrimental factors
that contribute towards this. The number of dimensions must increase
in order to accurately resolve the domain. The other factor is that
the growth of complexity of solutions can reduce the number of recurrences
drastically. There isn't really a manner to deal with the increasing
number of computational variables other than to wait for improvements
in computing power and memory availability. As for the recurrences, the
typical solution for increasingly rare events is to compute in parallel when
possible. The exponential growth in complexity makes even this proposition
a daunting one.
% The italicized text captures my sentiment of this next paragraph.
The \spt\ completely avoids this by constructing larger \twots\
from the combination of smaller \twots. That is,
we locate the fundamental tiles, which are easy to find due to their small
domain size, and then build them up to create larger \twots. The only
search required is the search for the fundamental tiles. To stress
this even further \textit{one of the challenges of turbulence
computations has been eliminated}. The reason
why the search for the fundamental tiles is classified as ``easy'' is because
in the small domain size limit there just aren't that many \twots; the dynamics
is relatively simple.
% I'm trying to say that the arbitrary choice of norm is not as impactful in our case....
Recurrence functions also require the introduction of a norm,
typically chosen without taking the geometry of the state space into account.
Points that are close in this norm can be far apart in a dynamical sense (\ie, on opposite sides
of an unstable manifold). An arbitrary norm is also chosen in the \spt\
context but there are some subtle differences. For starters, the
norm introduced in the \spt\ formulation is not beholden to dynamics, as
there are no longer any dynamics to speak of.
Additionally, the norm in the \spt\ case measures the distance between \twots,
not just single state space points. This is not a statement of proof but rather
a suggestion that the underlying topology improves the reliability of
the chosen norm. Restated in a different manner, the \spt\ norm
takes both the magnitude and phase into account.
%
Another numerical victory is that the \spt\ formulation is able to find solutions
of the \KSe\ starting from modulated random noise. The specifics
of ``modulated random noise'' are described in the numerical methods section
but it can essentially be thought of as randomly assigning values to \spt\
Fourier modes. The ability to find solutions from this starting point
is a radical improvement over the conventional capabilities. This is of course
in conjunction with allowing the \spt\ domain to change. The reaction to these
changes individually has induced skepticism and disbelief; together they comprise
a completely unheard of force.
%
The \spt\ formulation also includes the improvement of a commonly
practiced numerical method known as pseudo-arclength continuation.
The general idea is to track a solution as a parameter is varied. In the
Navier-Stokes equations this is typically the Reynolds number.
The improvement is due to our common refrain: the lack of dynamical
instability and the topological constraint of \twots. There can
be more confidence that if the continuation fails it is due to the solution
not existing rather than not being able to converge due to dynamical instability.

\bigskip
XXXXXXXXXXXXXXXXXXX
        \PC{2020-01-14}{
The remainder of the intro is the text written before Jan 14, 2020, reuse as
you see fit, then delete or move to \emph{GuBuCv17blog.tex} the rest.
        }

% Predrag                                           12 January 2016


In the dynamical systems approach,
theory of turbulence for a given system, with given boundary conditions,
is given by
(a) XXX and (b) XXX.

Flows described by partial differential equations (PDEs) are
said to be infinite dimensional because if one writes them
down as a set of ordinary differential equations (ODEs), a set
of infinitely many ODEs is needed to represent the dynamics
of one PDE. Even though their {\statesp} is thus
$\infty$-dimensional, the long-\-time dynamics of viscous
flows, such as Navier-Stokes, and PDEs modeling them, such as
Kuramoto-Sivashinsky, exhibits, when dissipation is high and
the system spatial extent small, apparent `low-dimensional'
dynamical behaviors. For some of these the asymptotic
dynamics is known to be confined to a finite-\-dimensional
{\em inertial manifold}.

For large spatial extent the complexity of the spatial
motions also needs to be taken into account. The systems
whose spatial correlations decay sufficiently fast, and the
attractor dimension and number of positive Lyapunov exponents
diverges with system size are said\rf{HNZks86,man90b,cross93}
to be extensive, `spatio-temporally chaotic' or `weakly
turbulent.'

There is no wide range of scales
involved, nor decay of spatial correlations, and the system
is in this sense only `chaotic.'

We pursue this program in context of the \KSe, % (KS) equation,
one of the simplest physically interesting spatially extended
nonlinear systems.

\PCedit{% 2019-04-17
We propose to study the evolution of \KS\ on the $1$\dmn\ infinite
spatial domain and develop a $2$\dmn\ symbolic dynamics for it: the
columns coding admissible time itineraries, and rows coding the
admissible spatial profiles.

The claim is that when the laws of motion
have several commuting continuous symmetries (time-translation
invariance; space-translation invariance), all continuous symmetries
directions should be treated democratically, as $(1+D)$ different
`times'. The proposal is inspired by the Gutkin and Osipov\rf{GutOsi15}
modelling of chain of $N$ coupled particle by temporal evolution of a
lattice of $N$ coupled cat maps.

Gutkin and Osipov\rf{GutOsi15} and Gutkin \etal\rf{GHJSC16}
discus recurrences in the \catlatt, by showing that
smaller recurring rectangular blocks shadow the {\spt} orbit
exponentially well for small lengths and short times.

A similar method might be applicable to pipe flows at
transitional Reynolds number, where the azimuthal and radial directions
are compact, and only the pipe length is infinite.
    }

We already have the two edges of this symbol plane - the $\speriod{}=22$ minimal
cell\rf{SCD07,lanCvit07} is sufficiently small that we can think of it as
a low-dimensional (``few-body'' in Gutkin and Klaus
Richter\rf{EPUR14,EDASRU14,EnUrRi15,EDUR15} condensed matter parlance)
dynamical system, the left-most column in the Gutkin and
Osipov\rf{GutOsi15} $2D$ symbolic dynamics {\spt} table (not a
1\dmn\ symbol sequence block), a column whose temporal symbolic dynamics
we will know, sooner or later. Michelson\rf{Mks86} has described the
bottom row, which, for continuous time, is discussed here in
\refsect{sect:KSeqva}, in Lan's thesis\rf{LanThesis} and his thesis-work
article\rf{lanCvit07}, unfortunately only for the reflection-invariant
subspace. The full Michelson \statesp\ is 4\dmn\ (3-dimensional dynamics
plus a parameter), and, in addition to the translation equivariance, it
is reflection equivariant which makes it \On{2}
equivariant, so slicing together with a \Zn{2} symmetry reduction is
required.

The goal of of our exploratory study would be to find a
set of {\rpo}s of the shortest period in both the time and the space
direction (with no imposition of a fixed, finite length $\speriod{}$ periodic
spatial domain).

We start in \refsect{sect:KStimeInt}  by reviewing the case considered in
all of the earlier, temporal-evolution literature, \KS\ on a spatial periodic
domain of fixed width $\speriod{}$, evolved for all times $\zeit$.
In \refsect{sect:KSspaceInt} we consider the case of temporally periodic
domain of fixed period $\period{}$,  for all positions $\conf$,
and
in \refsect{sect:KStwots} we consider {\spt}ly periodic torus, see
\reffig{fig:spaceTime1}.

%unused example of t=0 line in KSe
In the time independent case, the \KSe\ on the $T=0$ line,
there is exponential growth in complexity
as space tends towards infinity\rf{Mks86}. Inclusion of time
only makes this worse; how then, can infinite space-time ever
be explained? This question is answered by the existence
of very important solutions defined on small computational domains
which we have named \textit{fundamental tiles}. This is interesting
because the dynamics on these small \spt\ domains are typically
very simple; a result of there being few invariant solutions.
It is these tiles which shall form the foundation for the
\spt\ theory.

% siminos/spatiotemp/chapter/intro.tex
% $Author: predrag $ $Date: 2020-05-25 15:18:45 -0400 (Mon, 25 May 2020) $

% called by
%           siminos/spatiotemp/chapter/spatiotemp.tex
%           siminos/tiles/GuBuCv17.tex

%\section{Introduction}
%\label{sect:intro}
% Predrag                                           12 January 2016

%%%%%% an example for Matt - illustrates use of \edit for REFEREE resubmissions
\edit{
Recent experimental and theoretical advances\rf{science04}
support a dynamical vision of turbulence:
For any finite spatial resolution,
a turbulent flow follows approximately for a finite time
a pattern belonging to a
{ finite alphabet}
of admissible patterns.
The long term dynamics is
a {walk through the space of these unstable patterns}.
The question is how to characterize and classify such patterns?
} %end \edit

\MNG{2020-01-20}{ [Background] }
%\subsection{Background}
%	\subsubsection{The problem at hand}

Chaotic nonlinear systems constitute one of the few classical
physics problems yet to be solved. The behaviors exhibited are so peculiar
that it has permeated into popular culture via the butterfly effect.
This behavior poses a serious challenge which has
effects everything from weather prediction to
air travel.
%	\subsubsection{Minimal cells}
In the recent past computational successes were made
by studying turbulent flows on minimal cells: small domains that
could support turbulence and remain computationally tractable.
%	\subsubsection{ECS}
These successes came in form of time invariant solutions
alkso known as ``exact coherent structures''
(ECS)\rf{W01,WK04}. These solutions are important because it
is their unstable and stable manifolds that dictate the dynamics\rf{WFSBC15}.
%\subsubsection{large}
Not only have conventional methods not worked on large domains, we argue that
they never could have worked. The motivation behind minimal cells was to
develop an intuition for turbulence which would be used to obtain results
on progressively large domains.

%    \subsubsection{space-time is the new black}
In light of all of these difficulties
we believe that new bold ideas are required to resume forward progress.
We retreat from the conventional wisdom to start anew with a truly
{\spt} theory, one that treats infinite space-time as the shadowing
of a finite number of fundamental patterns which we denote as ``tiles''.


\MNG{2020-01-20}{ [Revolution] WHY?}
%\subsubsection{main motivation, treat dimensions equally}

The primary claim that we make is that in hindsight, describing turbulence
via an exponentially unstable dynamical equation never could have worked.
Conventional methods treat spatial dimensions
as finite and fixed and time as inherently infinite.
Our {\spt} formulation of chaos treats all continuous dimensions with translational
invariance democratically as $(1+D)$ different `times'.
The proposal is inspired by the Gutkin and Osipov\rf{GutOsi15}
modelling of chain of $N$ coupled particle by temporal evolution of a
lattice of $N$ coupled cat maps.

%\subsubsection{characterize and quantify all patterns}
The alternative that we propose to describe infinite space-time chaos via
the shadowing of fundamental patterns which we refer to as ``tiles''.
These tiles are the minimal ``building blocks'' of turbulence; they are realized
as \twots\ which are global solutions with compact support.
Finding the tiles of turbulence is fundamentally easier than finding
\twots\ on larger domains due to the exponential growth in complexity of
solutions. In other words there are fewer important solutions on smaller
domains. This in turn implies that there can only be a small
number of fundamental tiles. This is what makes the problem tractable:
if we can collect the complete set of tiles then we have the ability to
construct every \twot\ according to our theory.

%\subsubsection{no instabilities}
The lack of exponentially unstable dynamics has powerful and immediate effects.
Because there is no time integration, the problem of finding \twots\ is
now a variational one. The benefit of this is that there is no need to start
an initial guess on the attractor; the optimization process handles this
entirely. This allows us to find arbitrarily sized \twots but in fact
there is no need to. Our hypothesis is that we need only to find the
building blocks which shadow larger \twots\ and infinite space-time.

%\subsubsection{Large to small}
The {\spt} formulation allows a much easier categorization of what is
``fundamental'' by virtue of the frequency that patterns admit in the
collection of \twots. By identifying the most frequent patterns, we shall
clip these patterns out of the \twots\ they shadow and use them as initial
conditions to search for our tiles.


%\subsubsection{small to large}
The notion of ``building blocks of turbulence'' is one of the reasons for
studying fluid flows in the first place. There is evidence that certain
physical processes are fundamental, but they have yet to be used in a
constructive manner. The {\spt} description is able to actually put
these ideas in practice.
The \spt\ completely avoids this by constructing larger \twots\
from the combination of smaller \twots.
The reason
why the search for the fundamental tiles is classified as ``easy'' is because
in the small domain size limit there just aren't that many \twots; the dynamics
is relatively simple.

%\subsubsection{numerical benefits?}
The first key difference is that the governing equation
dictates the \spt\ domain size in an unsupervised
fashion. The results here are not
The only reason why $L$ was treated as fixed is due to the
inherent instability it includes when treated as a varying quantity.
This small detail, allowing the domain size $L$ to vary,
is not as trivial as it seems.
 This difficulty
is especially evident in the \KSe, whose spatial derivative terms
are of higher order than the first order time derivative, but also
there is a spatial derivative present in the nonlinear component.


%\subsubsection{easier to scale}

%\subsection{Transition}
%    \subsubsection{Advantages of spatiotemporal in place, what to do}

Specifically, we propose to study the evolution of \KS\ on the $2$\dmn\
infinite {\spt}domain and develop a $2$\dmn\ symbolic dynamics for it:
the columns coding admissible time itineraries, and rows coding the
admissible spatial profiles. Our {\spt} method is the clear winner in
both a computational and theoretical sense. By converting to a tile based
shadowing description we have essentially removed the confounding notion
of an infinite number of infinitely complex {\twots} from the discussion.
Now we must put these ideas into practice.
%\subsection{What}
%	\subsubsection{KSe, comparison with navier stokes}
The testing grounds for these ideas will be the \spt\ \KSe
% Are we relabeling all equations?
\beq \label{e-ks}
u_t + u_{xx} + u_{xxxx} + u u_x = 0 \quad \mbox{where} \quad x\in[0,\speriod{}], t\in[0,\period{}]
\eeq
where $u = u(x, t)$ represents a \spt\ velocity field. This
equation has been used to model many different processes such as
the laminar flame front velocity of Bunsen burners.
While \refeq{e-ks} is much simpler than the {\spt} Navier-Stokes equation,
we would argue that the main benefit is the simplicity of
visualizing its two-dimensional space-time. This visualization
makes the arguments more understandable and compelling in addition
to making the tiles easier to identify.
%\subsubsection{2-tori translational invariance, Fourier}
The translational invariance and periodicity of \refeq{e-ks} make
\spt\ Fourier modes a natural choice.
The inherently infinitely dimensional equations are approximated
by a Galerkin truncation of these \spt\ Fourier modes.
The \KSe\ \refeq{e-ks} in terms of the \Fcs\ $\Fu$ is a
system of differential algebraic equations
$\Fu$
\bea \label{e-kssFb}
%KSe in Fourier basis, pseudo-spectral form.
F(\Fu, \speriod{}, \period{}) &\equiv& (\omega - k^2 + k^4)\,\Fu + \frac{k}{2} \FFT(\IFFT(\Fu)^2)\,.
\eea
The nonlinear term is computed in a \emph{pseudospectral} fashion: a method which computes the
nonlinear term as a product in physical space as opposed to a convolution in spectral space.
The definitions of each term is as follows; $\FFT$ and $\IFFT$ represent the forward and backwards
\spt\ Fourier transform operators. Likewise, $\omega$ and $k$ contain the appropriate temporal and spatial frequencies to produce the corresponding derivatives. Any and all indices are withheld
to avoid unnecessary confusion at this stage.
%	\subsubsection{optimization problem (engineer's know how to solve)}
The {\spt} system of differential algebraic equations \refeq{e-kssFb}
is of the form $F(\Fu, \speriod{}, \period{})=0$. This type of optimization problem is ubiquitous in
engineering and optimization literature. Therefore solving \refeq{e-kssFb} is a matter of
adapting known numerical methods to its idiosyncracies.
%	\subsubsection{library of solutions}
Once we have the ability to solve \refeq{e-kssFb} we need to first create a collection
of \twots. The only requirement that the collection must satisfy is that it must capture
all fundamental patterns by adequately sampling the set of \twots. In other words an exhaustive
search is not our aim; not only that, but also the collection need not sample all {\spt} domain sizes.
We hypothesize that there is some upper bound on the {\spt} size of fundamental tiles due to {\spt}
correlation lengths.
%	\subsubsection{large to small}
Once the collection is deemed sufficient we proceed to visual inspection. In this manner
we determine the most frequent patterns and single them out as tile candidates. This is
done by literally clipping them out of the \twots\ that they shadow. Each clipping is
then treated as an initial guess for a fundamental tile which is itself a \twot. Therefore,
these represent initial conditions for the optimization method. It is not a guarantee
that every clipping converges to a \twot; therefore the number of attempts to find a tile
should continue until it does in fact converge. The number of convergence attempts is typically
proportional to how confident we are that the pattern being scrutinized is in fact a tile.
%	\subsubsection{small to large}
Once a collection of tiles is collected, we can construct new and reproduce known \twots.
This is completed with a method we refer to as ``gluing''. It is as straightforward as one
might infer: tiles are combined in a {\spt} array to form initial conditions used to find larger
\twots. Methods of gluing temporal sequences of \twots\ exist but never has the ability to
glue \twots\ spatiotemporally existed before.
%\subsubsection{symbolic dynamics}
With the implementation of the gluing method can begin to
probe the 2\dmn\ {\spt} symbolic dynamics
previously mentioned. A fully determined symbolic dynamics is sufficient
to describe infinite space-time completely.
We already have the two edges of this symbol plane - the $\speriod{}=22$ minimal
cell\rf{SCD07,lanCvit07} is sufficiently small that we can think of it as
a low-dimensional (``few-body'' in Gutkin and Klaus
Richter\rf{EPUR14,EDASRU14,EnUrRi15,EDUR15} condensed matter parlance)
dynamical system, the left-most column in the Gutkin and
Osipov\rf{GutOsi15} $2D$ symbolic dynamics {\spt} table (not a
1\dmn\ symbol sequence block), a column whose temporal symbolic dynamics
we will know, sooner or later. Michelson\rf{Mks86} has described the
bottom row. The remainder of the theory will be developed from the
bottom up, starting with small {\spt} blocks.

%\subsubsection{Summary and transition}
The plans for our {\spt} formulation have been laid bare. The main concept is that the infinities
of turbulence can be described by {\spt} symbolic dynamics whose letters are fundamental {\spt}
patterns. Consequentially, we have created numerical methods which not only perform better than
conventional methods but also present incredible newfound capabilities. These newfound capabilities
include but are not limited to finding small \twots\ which shadow larger \twots\ but also constructing
larger \twots\ from smaller ones. These new and robust methods alone present a way forward for turbulence research, hence their is merit in a {\spt} formulation even though the theory has not
been fully fleshed out.
%\subsection{Transition}
To test our \spt\ ideas we require three separate numerical methods: the first
should be able to find \twots\ of arbitrary domain size. The second needs to be able to
clip or extract tiles from these \twots. Lastly, we need a method of
gluing these tiles together. All three of these techniques require the ability
to solve the optimization problem $F(\Fu,\speriod{},\period{})=0$
on an arbitrarily sized doubly periodic domain.

\MNG{2020-02-18}{How?}
%\subsubsection{initial conditions}
As previously discussed, this work does not use
approximate recurrences or time integration
to generate initial conditions. Instead we simply
initialize a lattice of Fourier modes by first deciding
on the dimensions of the lattice and then assigning random
values to the modes. Specifically, random values in this case are
drawn from the standard normal distribution and then normalized
such that the physical field $u(x,t)$ has the assigned maximum value.
Manipulations of the Fourier spectrum can also be made but we have
no specific recommendation for how to do so as it can be rather
nonintuitive.

%\subsubsection{gradient descent}
The first method substitutes an equivalent optimization problem
instead of directly solving $F=0$. The optimization
problem is formed by the construction
of a scalar cost function
\beq
\mathcal{I}(\Fu,\speriod{},\period{}) = \frac{1}{2}||F(\Fu,\speriod{},\period{})||_2^2 \,.
\eeq
taking a derivative with respect to a fictitious time $\tau$
\bea \label{e-descent}
\frac{\partial \mathcal{I}}{\partial \tau}
&=& \nabla
\left(\frac{1}{2}||F(\Fu,\speriod{},\period{})||_2^2\right)
      \,\partial_{\tau}[\Fu,\speriod{},\period{}]
\continue
&=&
\left(\left[\frac{\partial F}{\partial \Fu},
           \frac{\partial F}{\partial \speriod{}},
           \frac{\partial F}{\partial \period{}}
       \right]^{\top} F(\Fu,\speriod{},\period{})
\right) \cdot \partial_{\tau}[\Fu,\speriod{},\period{}]
\continue
&\equiv& \left(J^{\top}F\right) \cdot \partial_{\tau}[\Fu,\speriod{},\period{}]
\;.
\eea
This equation \refeq{e-descent} by itself does not provide us with a
descent direction because $\partial_{\tau}[\Fu,\speriod{},\period{}]$
remains unspecified. The simplest choice is the negative gradient of the
cost function; this choice corresponds to the gradient descent algorithm.
\beq
\partial_{\tau}[\Fu,\speriod{},\period{}] = - \left(J^{\top}F\right) \,,
\eeq
such that
\beq
\frac{\partial \mathcal{I}}{\partial \tau}
= -\left|\left| \left(J^{\top}F\right)\right|\right|_2^2 \leq 0 \,.
\eeq
In order to ``descend'' we use Euler's method to integrate in the descent
direction. Note that this integration is with respect to fictitious time
and represents making successive variational corrections; it is not
dynamically unstable time integration. We elect to use a combination of
step limit and absolute tolerance to determine when the descent
terminates. If the cost function doesn't cross the threshold by the step
limit then the descent is terminated. The descent algorithm can be viewed
as a method of converging approximate solutions close enough to a final
\twot\ such that the least-squares algorithm can converge them, akin to
\refref{Faraz15}.

%\subsubsection{direct methods}
The second method is application of a least-squares solver
to the root finding problem $F=0$. The Newton system is
derived here for context.
\beq
F(\Fu+\delta\Fu, \speriod{}+\delta\speriod{},\period{}+\delta \period{})\approx
F(\Fu,\speriod{},\period{}) + J \cdot [\delta\Fu, \delta \speriod{}, \delta \period{}] + \dots \,.
\eeq
substitution of zero for the LHS (the root) yields
\beq \label{newton}
J \cdot [\delta\Fu, \delta \speriod{}, \delta \period{}] = -F(\Fu,\speriod{},\period{}) \,.
\eeq
where
\beq
J \equiv \left[\frac{\partial F}{\partial \Fu},
              \frac{\partial F}{\partial \speriod{}},
              \frac{\partial F}{\partial \period{}} \right] \,.
\eeq
Technically this equation is solved iteratively, each time producing its own least-squares solution which guides the field to \twot.
The equations are augmented to include variations in $\speriod{},\period{}$ and as
such the linear system is actually rectangular.
We chose to solve the equations in a least-squares manner as we are not focused on finding a unique
solution; any member of a \twots\ group orbit will do. The price of this indefiniteness is that we might
collect \twots\ which belong to the same group orbit. To improve the convergence rate of the algorithm we also include backtracking: the length of the Newton step is reduced until either a minimum length is reached (failure) or the cost function decreases.
%\subsubsection{transition to applications}
As a caveat, our specific least-squares
implementation is memory limited. That is, we can only apply it to some maximum dimension as it requires
the explicit construction of a large, dense matrix. Currently it suits our purposes such that we do not include any other numerical methods in this discussion.
The primary numerical methods that we apply have been described.
Now we can move onto describing exactly
how we used these method to further our \spt\ theory.

%\subsubsection{library}
As previously mentioned, we must first find a collection of \twots\ which we believe
adequately samples the space of \twots, up to some maximum size. We automated the search over a range
of periods and domain sizes. Periods were chosen from the range
$\period{}\in [20, 180]$. Meanwhile, the spatial range was $\speriod{} \in [22, 88]$. The discretization size
depended on the \spt\ domain size; more modes are needed to resolve larger solutions. The number
of lattice points in each dimension were typically chosen to be powers of two in order because of their interaction with discrete Fourier transforms. A strict rule for lattice size
was never developed so we offer is the approximate guidelines
\beq
M = 2^{\text{int}(\log_2(\speriod{})+1)}
\eeq
for space and
\beq
N = 2^{\text{int}(\log_2(\period{}))}\,.
\eeq
for time.
The tolerance of the cost function for the gradient descent was typically set at $10^{-4}$
and the step limit was set as a function of the size of the lattice. For the least-squares
with backtracking the tolerance for termination was originally $10^{-14}$ and the step limit was $500$. The large step limit was because of
the allowance of back-tracking, which reduces the step length.
The final tolerance can likely be relaxed as there is minimal change in solutions over many orders
of magnitude of the cost function; an indication that a different norm should be used.
%\subsubsection{clip}
As a reminder, our claim is that the tiles are \twots\ which shadow larger \twots.
Therefore we should be able to converge subdomains which have been numerically clipped out
of larger \twots. After visual inspection, we believed the number of fundamental tiles to
be small. Therefore, a precise and unsupervised algorithm for clipping was not developed.
Instead the only criteria we abided by is that the clipping must include the tile being
sought after; of course, clippings that were closer to being doubly periodic were sought after.
For the original \twot\ with dimensions $x \in [0, \speriod{0}]$ and $t \in [0, \period{0}]$ defined on a lattice, the
clipping can be described as follows. Find the approximate domain on which
the shadowing occurs and then literally extract the subregion of the parent lattice,
setting the new {\spt} dimensions according to the smaller lattice. In other words,
the same grid spacing was maintained throughout this procedure.
This process in combination with our numerical methods was sufficient
for finding tiles.
%\subsubsection{glue}
It is one thing to claim that certain \spt\ \twots\ are the building blocks
of turbulence for the \KSe. It is
another thing entirely to put our money where our mouth is by actually using them in this manner. We would like to remind the audience that the ability to construct and find solutions in this manner
has not been witnessed in the literature. With this in mind our choices should
be treated as preliminary ones; it is entirely possible and likely that
many improvements could be made.
Much like the clipping process used to find tiles combining solutions in space-time,
the overarching idea of gluing is straightforward and intuitive.
Specifically, the tiles represent the
Brillouin zone, fundamental domain, unit cell of a lattice, etc.
of each fundamental \twot.
The general case is that we have a general $s_n \times s_m$ sized mosaic of tiles.
The admissibility of the gluing is determined by the (currently unknown) symbolic
dynamics. Gluing is only well defined if the lattices being combined have the same
number of grid points along the gluing boundary.
This creates a problem, however, as
different tiles will have different \spt\ dimensions $\speriod{},\period{}$ because
they are fundamentally different solutions.
This actually helps provide a precise meaning to the term ``gluing''.
Gluing is a method of creating initial conditions which approximates
a non-uniform rectangular lattice (combination of tiles) as uniform.
This of course introduces local error which depends on the grid size; therefore
there should not be an extreme discrepancy between the \twots\ or tiles being glued.
With this in mind, we simply rediscretize and concatenate the new lattices.
The dimensions of the new lattice are determined by the sum or average of
the original dimensions.
For example, if gluing two tiles together in time, the new period would be
$\period{} = \period{1} + \period{2}$ but the new spatial period is
$\speriod{} = \frac{\speriod{1} + \speriod{2}}{2}$.
In this case the number of spatial grid \emph{points} and temporal grid \emph{spacing}
should be the same. There are many more complicated alternatives, limited only by
the imagination.
